{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1ae3eb",
   "metadata": {},
   "source": [
    "# Testing bundle adjust approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d36de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 images located\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rdcrlrka/.local/share/mamba/envs/skysat_stereo_snow/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from p_tqdm import p_map\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import re\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import json\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "\n",
    "# Define inputs\n",
    "data_path = '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/'\n",
    "img_folder = os.path.join(data_path, 'SkySatScene')\n",
    "refdem_file = os.path.join(data_path, '..', 'refdem', 'MCS_refdem_lidar_COPDEM_merged.tif')\n",
    "\n",
    "# Define output folders\n",
    "out_folder = os.path.join(data_path, 'proc_out')\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "new_img_folder = os.path.join(out_folder, 'single_band_images')\n",
    "camgen_folder = os.path.join(out_folder, 'camgen_cam_gcp')\n",
    "init_ortho_folder = os.path.join(out_folder, 'init_ortho')\n",
    "ba_triplet_folder = os.path.join(out_folder, 'bundle_adjust_triplets')\n",
    "ba_global_folder = os.path.join(out_folder, 'bundle_adjust_global')\n",
    "final_stereo_folder = os.path.join(out_folder, 'final_stereo')\n",
    "final_ortho_folder = os.path.join(out_folder, 'final_ortho')\n",
    "\n",
    "# Get images\n",
    "img_list = sorted(glob(os.path.join(img_folder, '*analytic.tif')))\n",
    "print(f\"{len(img_list)} images located\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ef0e1",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09b9aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(bin: str = None, \n",
    "            args: list = None, **kw) -> str:\n",
    "    binpath = shutil.which(bin)\n",
    "    if binpath.endswith('.py'):\n",
    "        call = ['python', binpath,]\n",
    "    else:\n",
    "        call = [binpath,]\n",
    "    if args is not None: \n",
    "        call.extend(args)\n",
    "    try:\n",
    "        out = subprocess.run(call,check=True,capture_output=True,encoding='UTF-8').stdout\n",
    "    except:\n",
    "        out = \"the command {} failed to run, see corresponding asp log\".format(call)\n",
    "    return out\n",
    "\n",
    "\n",
    "def run_gdal_merge(img_list: str = None,\n",
    "                   mosaic_fn: str = None,\n",
    "                   t_res: float | int = None,\n",
    "                   t_nodata: float | int = 0,\n",
    "                   t_dtype: str = 'UInt16'):\n",
    "    # Make sure output directory exists\n",
    "    if not os.path.exists(os.path.dirname(mosaic_fn)):\n",
    "        os.mkdir(os.path.dirname(mosaic_fn))\n",
    "\n",
    "    # Set up mosaic arguments\n",
    "    mos_args = ['-ot', t_dtype,\n",
    "                '-a_nodata', str(t_nodata)]\n",
    "    if t_res:\n",
    "        mos_args.extend(['-ps', str(t_res), str(t_res)])\n",
    "    mos_args.extend(['-o', mosaic_fn])\n",
    "    mos_args.extend(img_list)\n",
    "\n",
    "    # Run image mosaic\n",
    "    run_cmd('gdal_merge.py', mos_args)\n",
    "\n",
    "\n",
    "def generate_frame_cameras(\n",
    "        img_list = None,\n",
    "        dem_file: str = None, \n",
    "        product_level: str = 'l1b', \n",
    "        gcp_std: float = 1,\n",
    "        out_folder: str = None\n",
    "        ) -> str:\n",
    "    \"\"\"\n",
    "    Generate ASP camera models and GCPs for a list of images using cam_gen.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_list: list\n",
    "        list of image file names\n",
    "    dem_file: str\n",
    "        file name of the reference DEM\n",
    "    product_level: str\n",
    "        product level of the images, either 'l1b' or 'l1a'\n",
    "    out_folder: str\n",
    "        folder where output camera models and GCPs will be saved\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    cam_gen_log: str\n",
    "        file name of the cam_gen log file, which contains information about the number of GCP\n",
    "    \"\"\"\n",
    "    # Make output directory if it doesn't exist\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.mkdir(out_folder)\n",
    "    \n",
    "    cam_list = img_list\n",
    "\n",
    "    # Define output camera and GCP files\n",
    "    frames = [os.path.splitext(os.path.basename(x))[0] for x in img_list] # grab just the image identifier strings\n",
    "    out_cam_list = [os.path.join(out_folder,'{}.tsai'.format(frame)) for frame in frames]\n",
    "    out_gcp_list = [os.path.join(out_folder,'{}.gcp'.format(frame)) for frame in frames]\n",
    "\n",
    "    # Define reference height value where DEM has no data\n",
    "    ht_datum = np.nanmedian(rxr.open_rasterio(dem_file).squeeze().data) \n",
    "\n",
    "    # Determine number of jobs and threads per job\n",
    "    threads = os.cpu_count()\n",
    "    # ncpu, threads_per_job = 4, 3 #setup_parallel_jobs(total_jobs=len(img_list))\n",
    "        \n",
    "    # Iterate over images\n",
    "    log_list = []\n",
    "    for img, cam, out_cam, out_gcp in zip(img_list, cam_list, out_cam_list, out_gcp_list):\n",
    "        # construct arguments\n",
    "        args = [\n",
    "            '--threads', str(threads),\n",
    "            '--focal-length', str(553846.153846),\n",
    "            '--optical-center', str(1280), str(540),\n",
    "            '--height-above-datum', str(ht_datum),\n",
    "            '--gcp-std', str(gcp_std),\n",
    "            '--datum', 'WGS84',\n",
    "            '--reference-dem', dem_file,\n",
    "            '--refine-camera',\n",
    "            '--input-camera', cam,\n",
    "            '-o', out_cam,\n",
    "            '--gcp-file', out_gcp,\n",
    "            img\n",
    "        ]\n",
    "        if product_level=='l1b':\n",
    "            args += ['--pixel-pitch', str(0.8)]\n",
    "        else:\n",
    "            args += ['--pixel-pitch', str(1.0)]\n",
    "\n",
    "        # run command\n",
    "        log = run_cmd('cam_gen', args)\n",
    "        log_list += [log]\n",
    "\n",
    "    # Save compiled cam_gen log\n",
    "    cam_gen_log = os.path.join(out_folder, 'cam_gen.log')\n",
    "    print(\"Saving cam_gen log at {}\".format(cam_gen_log))\n",
    "    with open(cam_gen_log,'w') as f:\n",
    "        for log in log_list:\n",
    "            f.write(log + '\\n')\n",
    "    \n",
    "    # Remove basename from GCP file names\n",
    "    # ASP's cam_gen writes full path for images in the GCP files. This does not play well during bundle adjustment.\n",
    "    # The function returns a consolidated gcp file with all images paths only containing basenames so that bundle adjustment can roll along\n",
    "    # See ASP's gcp logic here: https://stereopipeline.readthedocs.io/en/latest/tools/bundle_adjust.html#bagcp\n",
    "    print(\"Writing GCPs with dirname removed\")  \n",
    "    def clean_img_in_gcp(row):\n",
    "        return os.path.basename(row[7])\n",
    "    for out_gcp in tqdm(out_gcp_list):\n",
    "        df = pd.read_csv(out_gcp, header=None,delimiter=r\"\\s+\")\n",
    "        df[7] = df.apply(clean_img_in_gcp, axis=1)\n",
    "        df[0] = np.arange(len(df))\n",
    "        out_fn = os.path.join(out_folder, os.path.basename(out_gcp).replace('.gcp', '_clean.gcp'))\n",
    "        df.to_csv(out_fn, sep=' ', index=False, header=False)\n",
    "\n",
    "    return cam_gen_log\n",
    "\n",
    "\n",
    "def calculate_baseline_to_height_ratio(\n",
    "        img1: str = None, \n",
    "        img2: str = None, \n",
    "        utm_epsg: str = None\n",
    "        ) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the baseline to height ratio for a pair of images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img1: str\n",
    "        file name of the first image\n",
    "    img2: str\n",
    "        file name of the second image\n",
    "    utm_epsg: str\n",
    "        EPSG code for the optimal UTM zone, e.g. \"EPSG:32601\"\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    b_h_ratio: float\n",
    "        baseline to height ratio, where baseline is the distance between camera centers and height is the average height of the two images\n",
    "    \"\"\"\n",
    "    # iterate over images\n",
    "    cams_list, h_list = [], []\n",
    "    for img in [img1, img2]:\n",
    "        # get camera center coordinates and heights\n",
    "        with rio.open(img) as src:\n",
    "            h = src.rpcs.height_off\n",
    "            lat = src.rpcs.lat_off\n",
    "            lon = src.rpcs.long_off\n",
    "        # reproject to UTM for distance calculations\n",
    "        gdf = gpd.GeoDataFrame(index=[0], geometry=[Point(lon, lat)], crs=\"EPSG:4326\")\n",
    "        gdf = gdf.to_crs(utm_epsg)\n",
    "        x = gdf.geometry[0].coords.xy[0][0]\n",
    "        y = gdf.geometry[0].coords.xy[0][0]\n",
    "        # save in arrays\n",
    "        cams_list += [[x,y]]\n",
    "        h_list += [h]\n",
    "    # calculate baseline\n",
    "    diff = np.array(cams_list[0]) - np.array(cams_list[1])\n",
    "    b = np.linalg.norm(diff)\n",
    "    h_mean = np.nanmean(np.array(h_list))\n",
    "    # calculate B/H ratio\n",
    "    return float(b / h_mean)\n",
    "\n",
    "\n",
    "def rpc_image_latlon_bounds(\n",
    "        img_fn: str = None, \n",
    "        height: float = 0.0\n",
    "        ) -> tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Get bounding box (min lon, min lat, max lon, max lat) for image with RPC metadata.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_fn: str\n",
    "        Path to image file with RPCs.\n",
    "    height: float\n",
    "        Ground height in meters used for projection.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple: [min_lon, min_lat, max_lon, max_lat]\n",
    "    \"\"\"\n",
    "    with rio.open(img_fn) as src:\n",
    "        if not src.rpcs:\n",
    "            raise ValueError(\"Image does not contain RPC metadata.\")\n",
    "\n",
    "        transformer = rio.transform.RPCTransformer(src.rpcs)\n",
    "\n",
    "        width = src.width\n",
    "        height_px = src.height\n",
    "\n",
    "        # Image corners (col, row)\n",
    "        pixel_coords = [\n",
    "            (0, 0),                    # top-left\n",
    "            (width - 1, 0),            # top-right\n",
    "            (width - 1, height_px - 1),# bottom-right\n",
    "            (0, height_px - 1)         # bottom-left\n",
    "        ]\n",
    "\n",
    "        cols, rows = zip(*pixel_coords)\n",
    "        zs = [height] * 4\n",
    "\n",
    "        lons, lats = transformer.xy(cols, rows, zs)\n",
    "\n",
    "        min_lon = float(np.min(lons))\n",
    "        max_lon = float(np.max(lons))\n",
    "        min_lat = float(np.min(lats))\n",
    "        max_lat = float(np.max(lats))\n",
    "\n",
    "        return min_lon, min_lat, max_lon, max_lat\n",
    "    \n",
    "\n",
    "def find_matching_camera_file(\n",
    "        image_fn: str = None, \n",
    "        cam_folder: str = None\n",
    "        ) -> str:\n",
    "    \"\"\"\n",
    "    Find camera file matching the image file's unique identifier.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_fn: str\n",
    "        file name of the image\n",
    "    cam_folder: str\n",
    "        folder containing camera files\n",
    "    Returns\n",
    "    ----------\n",
    "    matched_fn: str\n",
    "        file name of the matching camera file\n",
    "    \"\"\"\n",
    "    # Get the identifying string from the image file\n",
    "    # File naming convention SkySatScenes (https://developers.planet.com/docs/data/skysat/): \n",
    "    # <acquisition date>_<acquisition time>_<satellite_id><camera_id>_<frame_id>_<bandProduct>\n",
    "    match = re.search(r\"\\d{8}_\\d{6}_[a-zA-Z0-9]+_\\d{4}\", image_fn)\n",
    "    if match:\n",
    "        identifier = match.group(0)\n",
    "    else:\n",
    "        identifier = None\n",
    "    if not identifier:\n",
    "        raise ValueError(f\"Could not extract identifier from image: {image_fn}\")\n",
    "\n",
    "    # Find matching camera file(s)\n",
    "    cam_list = (glob(os.path.join(cam_folder, \"*.tsai\")) \n",
    "                + glob(os.path.join(cam_folder, '*.TXT')))\n",
    "    matched_fns = [f for f in cam_list if identifier in f]\n",
    "    # ideally, only one match, otherwise it's ambiguous\n",
    "    if len(matched_fns) == 0:\n",
    "        raise ValueError(f\"No matching camera file found for image: {image_fn}\")\n",
    "    elif len(matched_fns) > 1:\n",
    "        print(f\"Multiple matching camera files found for image: {image_fn}. \" \n",
    "              \"Returning the first one.\")\n",
    "        \n",
    "    return matched_fns[0]\n",
    "\n",
    "\n",
    "def setup_parallel_jobs(\n",
    "        total_jobs: int = None\n",
    "        ) -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Determine the number of parallel jobs to run and threads per job.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    total_jobs: int\n",
    "        The total number of jobs to run (e.g., number of stereo pairs).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    njobs: int\n",
    "        Number of parallel processes to run.\n",
    "    threads_per_job: int\n",
    "        Number of threads to allocate per process.\n",
    "    \"\"\"\n",
    "    total_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "    if total_jobs <= 1:\n",
    "        njobs = 1\n",
    "    elif total_jobs <= 10:\n",
    "        njobs = min(2, total_jobs)\n",
    "    elif total_jobs <= 100:\n",
    "        njobs = min(4, total_jobs)\n",
    "    else:\n",
    "        njobs = min(4, total_jobs)\n",
    "\n",
    "    threads_per_job = max(1, total_cpus // njobs)\n",
    "\n",
    "    print(f\"Will run {total_jobs} jobs across {njobs} CPU with {threads_per_job} threads per CPU\")\n",
    "\n",
    "    return njobs, threads_per_job\n",
    "\n",
    "\n",
    "def run_mapproject(\n",
    "        img_list: str = None, \n",
    "        cam_folder: str = None, \n",
    "        ba_prefix: str = None,\n",
    "        out_folder: str = None, \n",
    "        dem: str = 'WGS84', \n",
    "        t_res: float = None, \n",
    "        t_crs: str = None, \n",
    "        session: str = None, \n",
    "        orthomosaic: bool = False\n",
    "        ) -> None:\n",
    "    \"\"\"\n",
    "    Mapproject images onto a reference DEM and optionally, create median mosaic of mapprojected images. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_list: list of str\n",
    "        list of image file names\n",
    "    cam_folder: str\n",
    "        folder containing camera files\n",
    "    ba_prefix: str\n",
    "        bundle adjust prefix used to grab cameras or adjustments\n",
    "    out_folder: str\n",
    "        path to the folder where mapprojected images and cameras will be saved\n",
    "    dem: str (default=\"WGS84\")\n",
    "        reference DEM used for mapprojection. If None, will use the WGS84 datum.\n",
    "    t_res: float | str\n",
    "        target spatial resolution of the mapprojected images (meters)\n",
    "    t_crs: str\n",
    "        target coordinate reference system of the mapprojected images (e.g., \"EPSG:4326\")\n",
    "    session: str\n",
    "        ASP session type (e.g., \"pinhole\"). Usually, ASP can determine this automatically based on the inputs. \n",
    "    orthomosaic: bool\n",
    "        whether to create a median mosaic of the mapprojected images, along with count, NMAD, weighted average, \n",
    "        and mosaics from different stereo views\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    # Set up image specific arguments: output prefixes and cameras\n",
    "    frames_list = [os.path.splitext(os.path.basename(img))[0] for img in img_list]\n",
    "    out_list = [os.path.join(out_folder, img + '.tif') for img in frames_list]\n",
    "    cam_list = [find_matching_camera_file(img, cam_folder) for img in img_list]\n",
    "\n",
    "    # Determine number of threads to use per job\n",
    "    # ncpu, threads_per_job = setup_parallel_jobs(total_jobs=len(img_list))\n",
    "    # Mapproject is automatically splitting images into a single tile, \n",
    "    # so only one threads is needed for each image job\n",
    "    ncpu, threads_per_job = 12, 1\n",
    "\n",
    "    # Set up mapproject arguments\n",
    "    map_opts = [\n",
    "        '--threads', str(threads_per_job),\n",
    "        # limit to integer values, with 0 as no-data\n",
    "        '--nodata-value', '0',\n",
    "        '--ot', 'UInt16'\n",
    "        ]\n",
    "    if t_res:\n",
    "        map_opts += ['--tr', str(t_res)]\n",
    "    if t_crs:\n",
    "        map_opts += ['--t_srs', str(t_crs)]\n",
    "    if session:\n",
    "        map_opts += ['--session', session]\n",
    "    if ba_prefix:\n",
    "        map_opts += ['--bundle-adjust-prefix', ba_prefix]\n",
    "\n",
    "    # Set up jobs\n",
    "    jobs_list = []\n",
    "    for img, cam, out in tqdm(list(zip(img_list, cam_list, out_list))):\n",
    "        job = map_opts + [dem, img, cam, out]\n",
    "        jobs_list += [job]\n",
    "    print('\\nmapproject arguments for first job:')\n",
    "    print(jobs_list[0])\n",
    "    \n",
    "    # Run in parallel\n",
    "    log_list = p_map(run_cmd, ['mapproject']*len(jobs_list), jobs_list, num_cpus=ncpu)\n",
    "    \n",
    "    # Save compiled ortho log\n",
    "    ortho_log = os.path.join(out_folder, 'ortho.log')\n",
    "    print(\"Saving compiled orthorectification log at {}\".format(ortho_log))\n",
    "    with open(ortho_log,'w') as f:\n",
    "        for log in log_list:\n",
    "            f.write(log + '\\n')\n",
    "    \n",
    "    # Create orthomosaic\n",
    "    if orthomosaic:\n",
    "        print(\"\\nCreating orthomosaic\")\n",
    "        # get unique image datetimes\n",
    "        dt_list = list(set(sorted(['_'.join(os.path.basename(im).split('_')[0:2]) for im in out_list])))\n",
    "\n",
    "        # define mosaic prefix containing timestamps of inputs\n",
    "        mos_prefix = '__'.join(dt_list)\n",
    "\n",
    "        # define output filenames\n",
    "        mosaic_fn = os.path.join(out_folder, f'{mos_prefix}_orthomosaic.tif')\n",
    "\n",
    "        run_gdal_merge(\n",
    "            img_list=out_list, \n",
    "            mosaic_fn = mosaic_fn,\n",
    "            t_res = t_res\n",
    "            )\n",
    "\n",
    "\n",
    "def identify_overlapping_image_pairs(\n",
    "        img_list: str = None, \n",
    "        overlap_perc: float = 10, \n",
    "        bh_ratio_range: tuple = None,\n",
    "        true_stereo: bool = True,\n",
    "        utm_epsg: str = None,\n",
    "        out_folder: str = None,\n",
    "        write_basename: bool = False\n",
    "        )-> None:\n",
    "    # Make sure out_folder exists\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    # Get image bounds polygons\n",
    "    def get_image_polygon(img_fn):\n",
    "        # if no CRS, image is likely raw, ungeoregistered. Estimate using RPC.\n",
    "        crs = rxr.open_rasterio(img_fn).rio.crs\n",
    "        if not crs:\n",
    "            min_x, min_y, max_x, max_y = rpc_image_latlon_bounds(img_fn)\n",
    "            crs = \"EPSG:4326\"\n",
    "        # otherwise, use the embedded image bounds.\n",
    "        else:\n",
    "            min_x, min_y, max_x, max_y = rxr.open_rasterio(img_fn).rio.bounds()\n",
    "        # convert bounds to polygon\n",
    "        bounds_poly = Polygon([[min_x, min_y], [max_x, min_y],\n",
    "                                [max_x, max_y], [min_x, max_y],\n",
    "                                [min_x, min_y]])\n",
    "        # make sure bounds are in UTM projection\n",
    "        bounds_gdf = gpd.GeoDataFrame(index=[0], geometry=[bounds_poly], crs=crs)\n",
    "        bounds_gdf = bounds_gdf.to_crs(utm_epsg)\n",
    "\n",
    "        return bounds_gdf.geometry[0]\n",
    "    polygons = {img: get_image_polygon(img) for img in img_list}\n",
    "    \n",
    "    # Compare all unique pairs\n",
    "    print('Identifying stereo image pairs...')\n",
    "    print(f'Requirements:')\n",
    "    print(f'\\toverlap >= {overlap_perc} %')\n",
    "    if bh_ratio_range:\n",
    "        print(f'\\tbaseline to height ratio = {bh_ratio_range[0]} to {bh_ratio_range[1]}')\n",
    "    print(f'\\ttrue stereo = {true_stereo}')\n",
    "    overlapping_pairs = []\n",
    "    overlap_ratios = []\n",
    "    bh_ratios = []\n",
    "    # number of combos for progress bar\n",
    "    n = len(img_list)\n",
    "    total = n * (n - 1) // 2\n",
    "    for img1, img2 in tqdm(itertools.combinations(img_list, 2), total=total):\n",
    "        poly1 = polygons[img1]\n",
    "        poly2 = polygons[img2]\n",
    "\n",
    "        intersection = poly1.intersection(poly2)\n",
    "        if not intersection.is_empty:\n",
    "            area1 = poly1.area\n",
    "            area2 = poly2.area\n",
    "            overlap_percent = intersection.area / min(area1, area2) * 100\n",
    "            if overlap_percent >= overlap_perc:\n",
    "                # check for B/H ratio thresholds if specified\n",
    "                bh_ratio = calculate_baseline_to_height_ratio(img1, img2, utm_epsg)\n",
    "                if bh_ratio_range:\n",
    "                    if (bh_ratio < bh_ratio_range[0]) | (bh_ratio > bh_ratio_range[1]):\n",
    "                        continue\n",
    "                \n",
    "                # check for true stereo if specified - datetimes must be different\n",
    "                dt1 = '_'.join(os.path.basename(img1).split('_')[0:2])\n",
    "                dt2 = '_'.join(os.path.basename(img2).split('_')[0:2])\n",
    "                if true_stereo & (dt1==dt2):\n",
    "                    continue\n",
    "\n",
    "                bh_ratios += [bh_ratio]\n",
    "                overlapping_pairs += [(img1, img2)]\n",
    "                overlap_ratios += [overlap_percent]\n",
    "    print('Number of overlapping stereo pairs identified =', len(overlap_ratios))\n",
    "                    \n",
    "    # Write to file\n",
    "    out_fn = os.path.join(out_folder, 'overlapping_image_pairs.txt')\n",
    "    # add the header\n",
    "    with open(out_fn, 'w') as f:\n",
    "        f.write(f\"img1 img2 datetime_identifier overlap_percent bh_ratio\\n\")\n",
    "    # iterate over pairs\n",
    "    for i, (img1, img2) in enumerate(overlapping_pairs):\n",
    "        date1, time1 = os.path.basename(img1).split('_')[0:2]\n",
    "        date2, time2 = os.path.basename(img2).split('_')[0:2]\n",
    "        dt_text = date1 + '_' + time1 + '__' + date2 + '_' + time2\n",
    "        with open(out_fn, 'a') as f:\n",
    "            if write_basename:\n",
    "                if i==0:\n",
    "                    print('\\nWriting image pairs with basename only.')\n",
    "                f.write(f\"{os.path.basename(img1)} {os.path.basename(img2)} {dt_text} {overlap_ratios[i]} {bh_ratios[i]}\\n\")\n",
    "            else:\n",
    "                if i==0:\n",
    "                    print('Writing image pairs with full path name.')\n",
    "                f.write(f\"{img1} {img2} {dt_text} {overlap_ratios[i]} {bh_ratios[i]}\\n\")\n",
    "\n",
    "    print('Overlapping stereo pairs saved to file:', out_fn)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def create_triplets_pairs(overlap_txt, output_folder, high_overlap_thresh=65, max_group_size=4):\n",
    "    \"\"\"\n",
    "    Create overlapping triplet groups (for bundle adjust) and stereo pairs \n",
    "    from overlapping image data. Ensures each image belongs to exactly one triplet.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load overlap data\n",
    "    df = pd.read_csv(overlap_txt, sep=' ', header=0)\n",
    "\n",
    "    # Initialize tracking\n",
    "    groups_dict = {}\n",
    "    assigned = set()\n",
    "    image_list = set(df[['img1', 'img2']].values.flatten())\n",
    "    unassigned = set(image_list)\n",
    "\n",
    "    print(f\"Total images: {len(image_list)}\")\n",
    "\n",
    "    # --- Start with high-overlap pairs ---\n",
    "    df_max = df[df['overlap_percent'] > high_overlap_thresh].sort_values(by='overlap_percent', ascending=False)\n",
    "\n",
    "    i = 0\n",
    "    for _, row in df_max.iterrows():\n",
    "        img1, img2 = row['img1'], row['img2']\n",
    "        if img1 in assigned or img2 in assigned:\n",
    "            continue  # skip already used\n",
    "\n",
    "        # Find a third image overlapping strongly with either img1 or img2\n",
    "        df_third = df[\n",
    "            ((df['img1'].isin([img1, img2])) | (df['img2'].isin([img1, img2])))\n",
    "            & (~df['img1'].isin([img1, img2]))\n",
    "            & (~df['img2'].isin([img1, img2]))\n",
    "        ].sort_values(by='overlap_percent', ascending=False)\n",
    "\n",
    "        if not df_third.empty:\n",
    "            row3 = df_third.iloc[0]\n",
    "            img3 = row3['img1'] if row3['img1'] not in [img1, img2] else row3['img2']\n",
    "            group_imgs = [img1, img2, img3]\n",
    "        else:\n",
    "            group_imgs = [img1, img2]\n",
    "\n",
    "        # Save group\n",
    "        df_group = df[(df['img1'].isin(group_imgs)) & (df['img2'].isin(group_imgs))]\n",
    "        groups_dict[f'group_{i}'] = {\n",
    "            'file_names': group_imgs,\n",
    "            'length': len(group_imgs),\n",
    "            'overlap_percent_mean': float(df_group['overlap_percent'].mean()),\n",
    "            'bh_ratio_mean': float(df_group['bh_ratio'].mean())\n",
    "        }\n",
    "\n",
    "        assigned.update(group_imgs)\n",
    "        unassigned = image_list - assigned\n",
    "        i += 1\n",
    "\n",
    "    print(f\"After high-overlap grouping: {len(assigned)} assigned, {len(unassigned)} unassigned.\")\n",
    "\n",
    "    # --- Assign remaining images to best overlapping group ---\n",
    "    while unassigned:\n",
    "        ref_img = next(iter(unassigned))\n",
    "        df_img = df[(df['img1'] == ref_img) | (df['img2'] == ref_img)]\n",
    "        if df_img.empty:\n",
    "            # no overlaps — make its own group\n",
    "            groups_dict[f'group_{i}'] = {\n",
    "                'file_names': [ref_img],\n",
    "                'length': 1,\n",
    "                'overlap_percent_mean': 0.0,\n",
    "                'bh_ratio_mean': 0.0\n",
    "            }\n",
    "            assigned.add(ref_img)\n",
    "            unassigned = image_list - assigned\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # find the best overlapping assigned image\n",
    "        df_img_sorted = df_img.sort_values(by='overlap_percent', ascending=False)\n",
    "        for _, row in df_img_sorted.iterrows():\n",
    "            img_best = row['img1'] if row['img1'] != ref_img else row['img2']\n",
    "            found_group = None\n",
    "            for g, ginfo in groups_dict.items():\n",
    "                if img_best in ginfo['file_names']:\n",
    "                    found_group = g\n",
    "                    break\n",
    "            if found_group:\n",
    "                ginfo = groups_dict[found_group]\n",
    "                if ref_img not in ginfo['file_names']:\n",
    "                    ginfo['file_names'].append(ref_img)\n",
    "                    ginfo['length'] += 1\n",
    "                assigned.add(ref_img)\n",
    "                break\n",
    "        else:\n",
    "            # no overlapping assigned image — make a new pair\n",
    "            img_best = df_img_sorted.iloc[0]['img1'] if df_img_sorted.iloc[0]['img1'] != ref_img else df_img_sorted.iloc[0]['img2']\n",
    "            groups_dict[f'group_{i}'] = {\n",
    "                'file_names': [ref_img, img_best],\n",
    "                'length': 2,\n",
    "                'overlap_percent_mean': float(df_img_sorted.iloc[0]['overlap_percent']),\n",
    "                'bh_ratio_mean': float(df_img_sorted.iloc[0]['bh_ratio'])\n",
    "            }\n",
    "            assigned.update([ref_img, img_best])\n",
    "        unassigned = image_list - assigned\n",
    "        i += 1\n",
    "\n",
    "    print(f\"After assignment: {len(assigned)} assigned (should equal total images).\")\n",
    "\n",
    "    # --- Split large groups with overlap-preserving subgroups ---\n",
    "    new_groups_dict = {}\n",
    "    new_group_idx = 0\n",
    "\n",
    "    for _, ginfo in groups_dict.items():\n",
    "        files = ginfo['file_names']\n",
    "\n",
    "        if len(files) <= max_group_size:\n",
    "            new_groups_dict[f'group_{new_group_idx}'] = ginfo\n",
    "            new_group_idx += 1\n",
    "            continue\n",
    "\n",
    "        # Build overlap graph among images in this group\n",
    "        G = nx.Graph()\n",
    "        df_sub = df[(df['img1'].isin(files)) & (df['img2'].isin(files))]\n",
    "        for _, row in df_sub.iterrows():\n",
    "            G.add_edge(row['img1'], row['img2'], weight=row['overlap_percent'])\n",
    "\n",
    "        remaining = set(files)\n",
    "        while remaining:\n",
    "            if len(remaining) <= max_group_size:\n",
    "                sub_group = list(remaining)\n",
    "                remaining.clear()\n",
    "            else:\n",
    "                # start from node with highest degree (most connections)\n",
    "                node = max(remaining, key=lambda n: G.degree(n))\n",
    "                neighbors = sorted(\n",
    "                    [nbr for nbr in G.neighbors(node) if nbr in remaining],\n",
    "                    key=lambda n: G[node][n]['weight'],\n",
    "                    reverse=True\n",
    "                )\n",
    "                sub_group = [node] + neighbors[:max_group_size - 1]\n",
    "                remaining -= set(sub_group)\n",
    "                # overlap last node to maintain connection\n",
    "                if sub_group[-1] not in remaining:\n",
    "                    remaining.add(sub_group[-1])\n",
    "\n",
    "            # Save subgroup\n",
    "            df_group = df[(df['img1'].isin(sub_group)) | (df['img2'].isin(sub_group))]\n",
    "            new_groups_dict[f'group_{new_group_idx}'] = {\n",
    "                'file_names': sub_group,\n",
    "                'length': len(sub_group),\n",
    "                'overlap_percent_mean': float(df_group['overlap_percent'].mean()),\n",
    "                'bh_ratio_mean': float(df_group['bh_ratio'].mean())\n",
    "            }\n",
    "            new_group_idx += 1\n",
    "\n",
    "    print(f\"Final groups after splitting: {len(new_groups_dict)}\")\n",
    "\n",
    "    # --- Generate stereo pairs from triplets ---\n",
    "    stereo_pairs_list = []\n",
    "    for _, ginfo in new_groups_dict.items():\n",
    "        imgs = ginfo['file_names']\n",
    "        for pair in itertools.combinations(imgs, 2):\n",
    "            # check both orientations in df\n",
    "            mask = (\n",
    "                ((df['img1'] == pair[0]) & (df['img2'] == pair[1])) |\n",
    "                ((df['img1'] == pair[1]) & (df['img2'] == pair[0]))\n",
    "            )\n",
    "            df_pair = df.loc[mask]\n",
    "            # only add if not empty\n",
    "            if not df_pair.empty:\n",
    "                stereo_pairs_list.append(df_pair)\n",
    "    stereo_pairs = pd.concat(stereo_pairs_list, ignore_index=True).drop_duplicates(subset=['img1', 'img2'])\n",
    "\n",
    "    # --- Save outputs ---\n",
    "    # Save triplets as JSON to account to potentially different-sized groups\n",
    "    triplets_json = os.path.join(output_folder, 'bundle_adjust_triplets.json')\n",
    "    with open(triplets_json, 'w') as f:\n",
    "        json.dump(new_groups_dict, f, indent=2)\n",
    "    print(f\"Saved {len(new_groups_dict)} triplets to file:\", triplets_json)\n",
    "\n",
    "    # Save pairs as TXT for easier reading\n",
    "    stereo_pairs_txt = os.path.join(output_folder, 'stereo_pairs.txt')\n",
    "    stereo_pairs.to_csv(stereo_pairs_txt, sep=' ', header=True, index=False)\n",
    "    print(f\"Saved {len(stereo_pairs)} pairs to file:\", stereo_pairs_txt)\n",
    "\n",
    "    return triplets_json, stereo_pairs_txt\n",
    "\n",
    "\n",
    "def get_stereo_opts(\n",
    "        session: str = None, \n",
    "        threads: int = None, \n",
    "        texture: str = 'normal', \n",
    "        stop_point: int = -1, \n",
    "        unalign_disparity: bool = False\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Get the stereo options for the ASP parallel_stereo command.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    session: str (default=None)\n",
    "        The session type to use for stereo matching. Options include 'rpc', 'pinhole', etc. \n",
    "        ASP can often figure this out automatically. \n",
    "    threads: int (default=None)\n",
    "        Number of threads to use for parallel processing. If None, will automatically determine based on CPU count.\n",
    "    texture: str (default='normal')\n",
    "        This is used for determining the correlation and refinement kernel. Options = \"low\", \"normal\".\n",
    "    stop_point: int (default=-1)\n",
    "        Stopping point for stereo processing. Set to -1 to run all steps. Useful if only creating feature matches \n",
    "        or running image correlation, for example. See the ASP docs on stereo entry points for more information: \n",
    "        https://stereopipeline.readthedocs.io/en/latest/tools/parallel_stereo.html#entrypoints\n",
    "    unalign_disparity: bool (default=False)\n",
    "        Whether to generate disparity maps without alignment. This can be used for debugging or testing purposes.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    stereo_opt: list\n",
    "        A list of command line options for the ASP parallel_stereo command.\n",
    "    \"\"\"\n",
    "    stereo_opts = []\n",
    "    # session_args\n",
    "    if session:\n",
    "        stereo_opts.extend(['-t', session])\n",
    "    stereo_opts.extend(['--threads-multiprocess', str(threads)])\n",
    "    stereo_opts.extend(['--threads-singleprocess', str(threads)])\n",
    "    # stereo_pprc args : This is for preprocessing (adjusting image dynamic range, \n",
    "    # alignment using ip matches, etc.)\n",
    "    stereo_opts.extend(['--individually-normalize'])\n",
    "    stereo_opts.extend(['--ip-per-tile', '8000'])\n",
    "    stereo_opts.extend(['--ip-num-ransac-iterations','2000'])\n",
    "    stereo_opts.extend(['--force-reuse-match-files'])\n",
    "    stereo_opts.extend(['--skip-rough-homography'])\n",
    "    stereo_opts.extend(['--alignment-method', 'Affineepipolar'])\n",
    "    # mask out completely feature less area using a std filter, to avoid gross MGM errors\n",
    "    # this is experimental and needs more testing\n",
    "    stereo_opts.extend(['--stddev-mask-thresh', '0.5'])\n",
    "    stereo_opts.extend(['--stddev-mask-kernel', '-1'])\n",
    "    # stereo_corr_args\n",
    "    stereo_opts.extend(['--stereo-algorithm', 'asp_mgm'])\n",
    "    # correlation kernel size depends on the texture\n",
    "    if texture=='low':\n",
    "        stereo_opts.extend(['--corr-kernel', '9', '9'])\n",
    "    elif texture=='normal':\n",
    "        stereo_opts.extend(['--corr-kernel', '7', '7'])\n",
    "    stereo_opts.extend(['--corr-tile-size', '1024'])\n",
    "    stereo_opts.extend(['--cost-mode', '4'])\n",
    "    stereo_opts.extend(['--corr-max-levels', '5'])\n",
    "    # stereo_rfne_args:\n",
    "    stereo_opts.extend(['--subpixel-mode', '9'])\n",
    "    if texture=='low':\n",
    "        stereo_opts.extend(['--subpixel-kernel', '21', '21'])\n",
    "    elif texture=='normal':\n",
    "        stereo_opts.extend(['--subpixel-kernel', '15', '15'])\n",
    "    stereo_opts.extend(['--xcorr-threshold', '2'])\n",
    "    stereo_opts.extend(['--num-matches-from-disparity', '10000'])\n",
    "    # add stopping point if specified\n",
    "    if stop_point!=-1:\n",
    "        stereo_opts.extend(['--stop-point', str(stop_point)])\n",
    "    # get the disparity map without any alignment\n",
    "    if unalign_disparity:\n",
    "        stereo_opts.extend(['--unalign-disparity'])\n",
    "    \n",
    "    return stereo_opts\n",
    "\n",
    "\n",
    "def run_stereo(\n",
    "        stereo_pairs_fn: str = None, \n",
    "        cam_folder: str = None, \n",
    "        dem_file: str = None,\n",
    "        out_folder: str = None, \n",
    "        session: str = None,\n",
    "        texture: str = 'normal', \n",
    "        stop_point: int = -1\n",
    "        ) -> None:\n",
    "    \"\"\"\n",
    "    Execute stereo matching for SkySat images using the ASP parallel_stereo command.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stereo_pairs_fn: str (default=None)\n",
    "        Path to the text file containing overlapping image pairs.\n",
    "    cam_folder: str (default=None)\n",
    "        Path to the folder containing camera files. Required if using 'pinhole' session.\n",
    "    dem_file: str (default=None)\n",
    "\n",
    "    out_folder: str\n",
    "        Path to the folder where the output stereo results will be saved.\n",
    "    session: str (default=None)\n",
    "        The session type to use for stereo matching. Options include 'rpc', 'pinhole', etc. ASP can often figure this out automatically.\n",
    "    texture: str (default='normal')\n",
    "        How much relative texture there is in your images. This is used for determining the correlation and refinement kernel. \n",
    "        Options = \"low\", \"normal\". For example, a flat, snowy landscape likely has \"low\" texture. \n",
    "    stop_point: int\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Check if output folder exists\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.makedirs(out_folder)\n",
    "    \n",
    "    # Load the stereo pairs\n",
    "    stereo_pairs_df = pd.read_csv(stereo_pairs_fn, sep=' ', header=0)\n",
    "\n",
    "    # Determine number of CPUs for parallelization and threads per job\n",
    "    ncpu, threads_per_job = setup_parallel_jobs(total_jobs=len(stereo_pairs_df))\n",
    "    \n",
    "    # Define stereo arguments\n",
    "    stereo_opts = get_stereo_opts(\n",
    "        session=session, \n",
    "        threads=threads_per_job, \n",
    "        texture=texture, \n",
    "        stop_point=stop_point\n",
    "        )\n",
    "    \n",
    "    # Create jobs list for each stereo pair\n",
    "    job_list = []\n",
    "    for _, row in stereo_pairs_df.iterrows():\n",
    "        # Determine output folder for stereo job\n",
    "        IMG1 = os.path.splitext(os.path.basename(row['img1']))[0]\n",
    "        IMG2 = os.path.splitext(os.path.basename(row['img2']))[0]\n",
    "        out_prefix = os.path.join(out_folder, row['datetime_identifier'], IMG1 + '__' + IMG2, 'run')  \n",
    "\n",
    "        # SKIP PAIRS WITH MATCH FILES FOR NOW\n",
    "        if len(glob(out_prefix + '*.match')) > 0:\n",
    "            print(f'Match file already exists, skipping image pair: {os.path.basename(IMG1)}, {os.path.basename(IMG2)}')\n",
    "            continue\n",
    "\n",
    "        # Construct the stereo job\n",
    "        if cam_folder:\n",
    "            # Use the camera files if provided\n",
    "            cam1 = find_matching_camera_file(row['img1'], cam_folder)\n",
    "            cam2 = find_matching_camera_file(row['img2'], cam_folder)\n",
    "            job = stereo_opts + [row['img1'], cam1, row['img2'], cam2, out_prefix]\n",
    "        else:\n",
    "            # Otherwise, use the images directly\n",
    "            stereo_args = [row['img1'], row['img2'], out_prefix]\n",
    "            job = stereo_opts + stereo_args\n",
    "        # add DEM last\n",
    "        if dem_file:\n",
    "            job += [dem_file]\n",
    "\n",
    "        # Add job to list of jobs\n",
    "        job_list.append(job)\n",
    "    \n",
    "    # Run the jobs in parallel\n",
    "    print('stereo arguments for first job:')\n",
    "    print(job_list[0])\n",
    "    stereo_logs = p_map(run_cmd, ['parallel_stereo']*len(job_list), job_list, num_cpus=ncpu)\n",
    "\n",
    "    # Save the consolidated log\n",
    "    stereo_log_fn = os.path.join(out_folder, 'stereo_log.log')\n",
    "    with open(stereo_log_fn, 'w') as f:\n",
    "        for log in stereo_logs:\n",
    "            f.write(log + '\\n')\n",
    "    print(\"Consolidated stereo log saved at {}\".format(stereo_log_fn))\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def copy_match_files(matches_folder, image_files, output_prefix, verbose=True):\n",
    "    # get match files from output_folder and any subfolders\n",
    "    match_list = sorted(glob(os.path.join(matches_folder, '*.match')))\n",
    "    if not match_list:\n",
    "        match_list = sorted(glob(os.path.join(matches_folder, '*', '*.match')))\n",
    "    if not match_list:\n",
    "        match_list = sorted(glob(os.path.join(matches_folder, '*', '*', '*.match')))\n",
    "\n",
    "    # subset to pairs in the image list\n",
    "    image_list_base = [\n",
    "        os.path.splitext(os.path.basename(x))[0].replace('run-','') \n",
    "        for x in image_files\n",
    "        ]\n",
    "    match_list = [\n",
    "        x for x in match_list \n",
    "        if (os.path.dirname(x).split('/')[-1].split('__')[0] in image_list_base)\n",
    "        & (os.path.dirname(x).split('/')[-1].split('__')[1] in image_list_base)\n",
    "        ]\n",
    "    if verbose:\n",
    "        print(f'Copying {len(match_list)} matches to output folder')\n",
    "\n",
    "    for match_file in match_list:\n",
    "        match_out_file = (\n",
    "            output_prefix + '-' \n",
    "            + os.path.dirname(match_file).split('/')[-1] \n",
    "            + '.match'\n",
    "            )\n",
    "        _ = shutil.copy2(match_file, match_out_file)\n",
    "\n",
    "\n",
    "def reduce_asp_match_files(\n",
    "        match_folder: str = None, \n",
    "        output_folder: str = None,\n",
    "        num_pts: int = 100\n",
    "        ):\n",
    "\n",
    "    # Check if matches are nested in match_folder\n",
    "    match_files = sorted(glob(os.path.join(match_folder, '*.match')))\n",
    "    if not match_files:\n",
    "        match_files = sorted(glob(os.path.join(match_folder, '*', '*.match')))\n",
    "        match_folder_glob = os.path.join(match_folder, '*')\n",
    "    if not match_files:\n",
    "        match_files = sorted(glob(os.path.join(match_folder, '*', '*', '*.match')))\n",
    "        match_folder_glob = os.path.join(match_folder, '*', '*')\n",
    "\n",
    "    print(f'Reducing the number of feature matches to ~{num_pts} for {len(match_files)} match files.')\n",
    "\n",
    "    # Convert match files from binary -> text\n",
    "    for match_file in tqdm(match_files, desc='Parsing'):\n",
    "        txt_out = match_file.replace('.match', '_match.txt')\n",
    "        if not os.path.exists(txt_out):\n",
    "            cmd = [match_file, txt_out]\n",
    "            run_cmd('parse_match_file.py', cmd)\n",
    "\n",
    "    # Reduce the number of feature matches\n",
    "    match_txt_files = sorted(glob(os.path.join(match_folder_glob, '*_match.txt')))\n",
    "    for match_txt_file in tqdm(match_txt_files, desc='Reducing'):\n",
    "        with open(match_txt_file, 'r') as f:\n",
    "            lines = [l.strip() for l in f if l.strip()]\n",
    "\n",
    "        if not lines:\n",
    "            print(f\"Empty match file: {match_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        # Parse header (number of match points per image)\n",
    "        try:\n",
    "            n1, n2 = np.array(lines[0].split()).astype(int)\n",
    "        except Exception as e:\n",
    "            print(f\"Invalid header in {match_txt_file}: {lines[0]}\")\n",
    "            continue\n",
    "\n",
    "        img1_matches = lines[1:1+n1]\n",
    "        img2_matches = lines[1+n1:1+n1+n2]\n",
    "\n",
    "        if not img1_matches or not img2_matches:\n",
    "            print(f\"Skipping incomplete match file: {match_txt_file}\")\n",
    "            continue\n",
    "\n",
    "        # Subsample\n",
    "        new_samps = max(1, int(n1 / num_pts))\n",
    "        img1_matches = img1_matches[::new_samps]\n",
    "        img2_matches = img2_matches[::new_samps]\n",
    "\n",
    "        # Update header\n",
    "        n1_new = len(img1_matches)\n",
    "        n2_new = len(img2_matches)\n",
    "        header_line = f\"{n1_new} {n2_new}\"\n",
    "\n",
    "        # Write reduced match text\n",
    "        match_txt_out = match_txt_file.replace('.txt', '_reduced.txt')\n",
    "        with open(match_txt_out, 'w') as f:\n",
    "            f.write(header_line + '\\n')\n",
    "            f.write('\\n'.join(img1_matches) + '\\n')\n",
    "            f.write('\\n'.join(img2_matches) + '\\n')\n",
    "\n",
    "    # Convert reduced text -> binary\n",
    "    match_txt_reduced_files = glob(os.path.join(match_folder_glob, '*_reduced.txt'))\n",
    "    for match_file in tqdm(match_txt_reduced_files, desc='Re-parsing'):\n",
    "        subdir_name = os.path.dirname(match_file).split('/')[-1]\n",
    "        if not output_folder:\n",
    "            match_out_file = os.path.join(os.path.dirname(match_file), f'run-{subdir_name}.match')\n",
    "        else:\n",
    "            match_out_file = os.path.join(output_folder, f'run-{subdir_name}.match')\n",
    "        cmd = ['-rev', match_file, match_out_file]\n",
    "        run_cmd('parse_match_file.py', cmd)\n",
    "\n",
    "    print('Match file point reduction complete.')\n",
    "    return\n",
    "\n",
    "\n",
    "def run_ba(\n",
    "        image_list: list[str] = None, \n",
    "        cam_folder: str = None, \n",
    "        output_prefix: str = None,\n",
    "        refdem_file: str = None, \n",
    "        refdem_uncertainty: float = 5, \n",
    "        skip_matching: bool = False,\n",
    "        threads_string: str = \"all\",\n",
    "        verbose: bool = True\n",
    "        ):\n",
    "    output_folder = os.path.dirname(output_prefix)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # determine how many threads to use\n",
    "    if threads_string==\"all\":\n",
    "        threads = os.cpu_count()\n",
    "    else:\n",
    "        threads = int(threads_string)\n",
    "    if verbose:\n",
    "        print(f'Using up to {threads} threads for each process.')\n",
    "\n",
    "    # get the cameras for each image\n",
    "    cam_list = [find_matching_camera_file(x, cam_folder) for x in image_list]\n",
    "\n",
    "    # construct the arguments\n",
    "    args = [\n",
    "        \"--threads\", str(threads),\n",
    "        \"--num-iterations\", \"500\",\n",
    "        \"--num-passes\", \"2\",\n",
    "        \"--inline-adjustments\",\n",
    "        \"--save-cnet-as-csv\",\n",
    "        \"--min-matches\", \"4\",\n",
    "        \"--disable-tri-ip-filter\",\n",
    "        \"--ip-per-tile\", \"4000\",\n",
    "        \"--ip-inlier-factor\", \"0.2\",\n",
    "        \"--ip-num-ransac-iterations\", \"1000\",\n",
    "        \"--skip-rough-homography\", \n",
    "        \"--min-triangulation-angle\", \"0.0001\",\n",
    "        \"--remove-outliers-params\", \"75 3 5 6\",\n",
    "        \"--individually-normalize\",\n",
    "        \"-o\", output_prefix\n",
    "        ] + image_list + cam_list\n",
    "\n",
    "    if skip_matching:\n",
    "        args += [\"--force-reuse-match-files\"]\n",
    "        args += [\"--skip-matching\"]\n",
    "    if refdem_file:\n",
    "        args += [\"--heights-from-dem\", refdem_file]\n",
    "        args += [\"--heights-from-dem-uncertainty\", str(refdem_uncertainty)]\n",
    "\n",
    "    # run bundle adjust\n",
    "    log = run_cmd('parallel_bundle_adjust', args)\n",
    "\n",
    "    # write log to file\n",
    "    dt_now = datetime.now()\n",
    "    dt_now_string = str(dt_now).replace('-','').replace(' ','').replace(':','').replace('.','')\n",
    "    log_file = output_prefix + f'-parallel_bundle_adjust_{dt_now_string}.log'\n",
    "    with open(log_file, 'w') as f:\n",
    "        f.write(log)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Saved compiled log to file:', log_file)\n",
    "        print('Bundle adjust complete.')\n",
    "        \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3998cd",
   "metadata": {},
   "source": [
    "## Convert images to single band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51048f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(new_img_folder, exist_ok=True)\n",
    "\n",
    "print('Saving first band of each image. Only single-band images allowed by ASP.')\n",
    "for img in tqdm(img_list):\n",
    "    out_img = os.path.join(new_img_folder, os.path.basename(img))\n",
    "    if os.path.exists(out_img):\n",
    "        continue\n",
    "    args = [\n",
    "        \"-b\", \"1\",\n",
    "        img, out_img\n",
    "    ]\n",
    "    run_cmd(\"gdal_translate\", args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed1a0bd",
   "metadata": {},
   "source": [
    "## Generate frame cameras and GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(camgen_folder, exist_ok=True)\n",
    "\n",
    "generate_frame_cameras(\n",
    "    img_list = sorted(glob(os.path.join(new_img_folder, '*.tif'))),\n",
    "    dem_file = refdem_file, \n",
    "    product_level = 'l1b',\n",
    "    out_folder = camgen_folder,\n",
    "    gcp_std = 5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7941d3",
   "metadata": {},
   "source": [
    "## Try camera_solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74ccd2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating reconstruction using Theia\n",
      "export_reconstruction_to_vw --reconstruction /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/theia_reconstruction.dat --output_directory /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve --images /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/*.tif\n",
      "Exporting parameters for image: 20240420_165753_ssc16d1_0010_basic_analytic.tif\n",
      "Writing: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165753_ssc16d1_0010_basic_analytic.tif.tsai\n",
      "Exporting parameters for image: 20240420_165753_ssc16d1_0009_basic_analytic.tif\n",
      "Writing: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165753_ssc16d1_0009_basic_analytic.tif.tsai\n",
      "Exporting parameters for image: 20240420_165725_ssc16d1_0009_basic_analytic.tif\n",
      "Writing: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165725_ssc16d1_0009_basic_analytic.tif.tsai\n",
      "Exporting parameters for image: 20240420_165822_ssc16d1_0008_basic_analytic.tif\n",
      "Writing: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165822_ssc16d1_0008_basic_analytic.tif.tsai\n",
      "\n",
      "\n",
      "Finished extracting camera models\n",
      "export_matches_file_to_vw -theia_match_dir /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/match_dir -vw_output_prefix /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out\n",
      "Loaded 6 pairs of matches.\n",
      "Writing 544 matches to /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165725_ssc16d1_0009_basic_analy__20240420_165753_ssc16d1_0009_basic_analy.match\n",
      "Writing 881 matches to /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165725_ssc16d1_0009_basic_analy__20240420_165753_ssc16d1_0010_basic_analy.match\n",
      "Writing 166 matches to /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165725_ssc16d1_0009_basic_analy__20240420_165822_ssc16d1_0008_basic_analy.match\n",
      "Writing 2229 matches to /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0009_basic_analy__20240420_165753_ssc16d1_0010_basic_analy.match\n",
      "Writing 1196 matches to /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0009_basic_analy__20240420_165822_ssc16d1_0008_basic_analy.match\n",
      "Writing 1083 matches to /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0010_basic_analy__20240420_165822_ssc16d1_0008_basic_analy.match\n",
      "\n",
      "\n",
      "bundle_adjust --no-datum /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165725_ssc16d1_0009_basic_analytic.tif.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165753_ssc16d1_0009_basic_analytic.tif.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165753_ssc16d1_0010_basic_analytic.tif.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165822_ssc16d1_0008_basic_analytic.tif.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165725_ssc16d1_0009_basic_analytic.gcp /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165753_ssc16d1_0009_basic_analytic.gcp /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165753_ssc16d1_0010_basic_analytic.gcp /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165822_ssc16d1_0008_basic_analytic.gcp -o /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out --inline-adjustments -t nadirpinhole --datum wgs84 --transform-cameras-with-shared-gcp\n",
      "\t--> Setting number of processing threads to: 4\n",
      "Writing log: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-log-bundle_adjust-10-28-1423-70658.txt\n",
      "Loading camera model: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165725_ssc16d1_0009_basic_analytic.tif.tsai\n",
      "Datum:\n",
      "Geodetic Datum --> Name: WGS_1984  Spheroid: WGS 84  Semi-major axis: 6378137  Semi-minor axis: 6356752.3142451793  Meridian: Greenwich at 0  Proj4 Str: +proj=longlat +datum=WGS84 +no_defs\n",
      "Loading the cameras.\n",
      "Using session: nadirpinhole\n",
      "Loading cameras elapsed time: 0.00038 seconds.\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165725_ssc16d1_0009_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif: [ lo: 3178 hi: 36066 mean: 12305.3 std_dev: 9117.24 ]\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0009_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif: [ lo: 3445 hi: 40184 mean: 18162.2 std_dev: 10622.2 ]\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0010_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif: [ lo: 3310 hi: 40780 mean: 18730.3 std_dev: 10424.1 ]\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165822_ssc16d1_0008_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif: [ lo: 3935 hi: 39128 mean: 16908.1 std_dev: 9983.07 ]\n",
      "Using session: nadirpinhole\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165725_ssc16d1_0009_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif: [ lo: 3178 hi: 36066 mean: 12305.3 std_dev: 9117.24 ]\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0009_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif: [ lo: 3445 hi: 40184 mean: 18162.2 std_dev: 10622.2 ]\n",
      "\t--> Matching interest points in StereoSession.\n",
      "\t    Using 1 thread(s) for matching.\n",
      "\t    Not using a datum in interest point matching.\n",
      "\t--> Matching interest points using homography.\n",
      "\t    Looking for IP in left image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165725_ssc16d1_0009_basic_analytic.vwip\n",
      "\t    Looking for IP in right image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0009_basic_analytic.vwip\n",
      "Elapsed time in ip detection: 0.000449 s.\n",
      "\t--> Uniqueness threshold: 0.8\n",
      "           Matching: [****************************************************]\n",
      "Elapsed time in ip matching: 1.3e-05 s.\n",
      "\t    Matched points: 0\n",
      "Could not find interest points between images /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif and /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif\n",
      "Warning: Unable to find enough interest point matches in the images. Check if the images are similar enough in illumination and if they have enough overlap.\n",
      "\n",
      "Using session: nadirpinhole\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165725_ssc16d1_0009_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif: [ lo: 3178 hi: 36066 mean: 12305.3 std_dev: 9117.24 ]\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0010_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif: [ lo: 3310 hi: 40780 mean: 18730.3 std_dev: 10424.1 ]\n",
      "\t--> Matching interest points in StereoSession.\n",
      "\t    Using 1 thread(s) for matching.\n",
      "\t    Not using a datum in interest point matching.\n",
      "\t--> Matching interest points using homography.\n",
      "\t    Looking for IP in left image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165725_ssc16d1_0009_basic_analytic.vwip\n",
      "\t    Looking for IP in right image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0010_basic_analytic.vwip\n",
      "Elapsed time in ip detection: 0.000383 s.\n",
      "\t--> Uniqueness threshold: 0.8\n",
      "           Matching: [****************************************************]\n",
      "Elapsed time in ip matching: 7e-06 s.\n",
      "\t    Matched points: 0\n",
      "Could not find interest points between images /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif and /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif\n",
      "Warning: Unable to find enough interest point matches in the images. Check if the images are similar enough in illumination and if they have enough overlap.\n",
      "\n",
      "Using session: nadirpinhole\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165725_ssc16d1_0009_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif: [ lo: 3178 hi: 36066 mean: 12305.3 std_dev: 9117.24 ]\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165822_ssc16d1_0008_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif: [ lo: 3935 hi: 39128 mean: 16908.1 std_dev: 9983.07 ]\n",
      "\t--> Matching interest points in StereoSession.\n",
      "\t    Using 1 thread(s) for matching.\n",
      "\t    Not using a datum in interest point matching.\n",
      "\t--> Matching interest points using homography.\n",
      "\t    Looking for IP in left image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165725_ssc16d1_0009_basic_analytic.vwip\n",
      "\t    Looking for IP in right image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165822_ssc16d1_0008_basic_analytic.vwip\n",
      "Elapsed time in ip detection: 0.001001 s.\n",
      "\t--> Uniqueness threshold: 0.8\n",
      "           Matching: [****************************************************]\n",
      "Elapsed time in ip matching: 7e-06 s.\n",
      "\t    Matched points: 0\n",
      "Could not find interest points between images /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif and /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif\n",
      "Warning: Unable to find enough interest point matches in the images. Check if the images are similar enough in illumination and if they have enough overlap.\n",
      "\n",
      "Using session: nadirpinhole\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0009_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif: [ lo: 3445 hi: 40184 mean: 18162.2 std_dev: 10622.2 ]\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0010_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif: [ lo: 3310 hi: 40780 mean: 18730.3 std_dev: 10424.1 ]\n",
      "\t--> Matching interest points in StereoSession.\n",
      "\t    Using 1 thread(s) for matching.\n",
      "\t    Not using a datum in interest point matching.\n",
      "\t--> Matching interest points using homography.\n",
      "\t    Looking for IP in left image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0009_basic_analytic.vwip\n",
      "\t    Looking for IP in right image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0010_basic_analytic.vwip\n",
      "Elapsed time in ip detection: 0.000522 s.\n",
      "\t--> Uniqueness threshold: 0.8\n",
      "           Matching: [****************************************************]\n",
      "Elapsed time in ip matching: 7e-06 s.\n",
      "\t    Matched points: 0\n",
      "Could not find interest points between images /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif and /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif\n",
      "Warning: Unable to find enough interest point matches in the images. Check if the images are similar enough in illumination and if they have enough overlap.\n",
      "\n",
      "Using session: nadirpinhole\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0009_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif: [ lo: 3445 hi: 40184 mean: 18162.2 std_dev: 10622.2 ]\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165822_ssc16d1_0008_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif: [ lo: 3935 hi: 39128 mean: 16908.1 std_dev: 9983.07 ]\n",
      "\t--> Matching interest points in StereoSession.\n",
      "\t    Using 1 thread(s) for matching.\n",
      "\t    Not using a datum in interest point matching.\n",
      "\t--> Matching interest points using homography.\n",
      "\t    Looking for IP in left image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0009_basic_analytic.vwip\n",
      "\t    Looking for IP in right image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165822_ssc16d1_0008_basic_analytic.vwip\n",
      "Elapsed time in ip detection: 0.00035 s.\n",
      "\t--> Uniqueness threshold: 0.8\n",
      "           Matching: [****************************************************]\n",
      "Elapsed time in ip matching: 7e-06 s.\n",
      "\t    Matched points: 0\n",
      "Could not find interest points between images /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif and /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif\n",
      "Warning: Unable to find enough interest point matches in the images. Check if the images are similar enough in illumination and if they have enough overlap.\n",
      "\n",
      "Using session: nadirpinhole\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0010_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif: [ lo: 3310 hi: 40780 mean: 18730.3 std_dev: 10424.1 ]\n",
      "Computing statistics for /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif\n",
      "\t--> Reading statistics from file /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165822_ssc16d1_0008_basic_analytic-stats.tif\n",
      "\t    /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif: [ lo: 3935 hi: 39128 mean: 16908.1 std_dev: 9983.07 ]\n",
      "\t--> Matching interest points in StereoSession.\n",
      "\t    Using 1 thread(s) for matching.\n",
      "\t    Not using a datum in interest point matching.\n",
      "\t--> Matching interest points using homography.\n",
      "\t    Looking for IP in left image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165753_ssc16d1_0010_basic_analytic.vwip\n",
      "\t    Looking for IP in right image.\n",
      "\t    Using 5000 interest points per tile (1024^2 px).\n",
      "\t    Detecting IP\n",
      "\t    Removing IP near nodata with radius 4\n",
      "\t    Building descriptors\n",
      "\t    Number of interest points: 0\n",
      "\t    Writing interest points: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out-20240420_165822_ssc16d1_0008_basic_analytic.vwip\n",
      "Elapsed time in ip detection: 0.000321 s.\n",
      "\t--> Uniqueness threshold: 0.8\n",
      "           Matching: [****************************************************]\n",
      "Elapsed time in ip matching: 6e-06 s.\n",
      "\t    Matched points: 0\n",
      "Could not find interest points between images /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif and /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif\n",
      "Warning: Unable to find enough interest point matches in the images. Check if the images are similar enough in illumination and if they have enough overlap.\n",
      "\n",
      "Loaded 0 matches from all files.\n",
      "Failed to build a control network.\n",
      " - Consider removing all .vwip and .match files and \n",
      "   increasing the number of interest points per tile using\n",
      "    --ip-per-tile, or decreasing --min-matches.\n",
      " - Check if your images are similar enough in illumination,\n",
      "   and if they have enough overlap.\n",
      "Will continue if ground control points are present.\n",
      "Found 4 ground control point files.\n",
      "Loading GCP file: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165725_ssc16d1_0009_basic_analytic.gcp\n",
      "Loading GCP file: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165753_ssc16d1_0009_basic_analytic.gcp\n",
      "Loading GCP file: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165753_ssc16d1_0010_basic_analytic.gcp\n",
      "Loading GCP file: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165822_ssc16d1_0008_basic_analytic.gcp\n",
      "Loaded 32 ground control points.\n",
      "Applying transform to cameras given several GCP shared among the images.\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99307e+06,-4.14639e+06,4.40604e+06)] 0:Vector2(0,0) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99056e+06,-4.14697e+06,4.40597e+06)] 0:Vector2(2559,0) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99073e+06,-4.14746e+06,4.40527e+06)] 0:Vector2(2559,1079) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99327e+06,-4.1469e+06,4.40536e+06)] 0:Vector2(0,1079) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99246e+06,-4.14664e+06,4.40583e+06)] 0:Vector2(640,270) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99122e+06,-4.14694e+06,4.4058e+06)] 0:Vector2(1920,270) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99127e+06,-4.14716e+06,4.40543e+06)] 0:Vector2(1920,810) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99256e+06,-4.14689e+06,4.40548e+06)] 0:Vector2(640,810) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99322e+06,-4.14611e+06,4.40643e+06)] 1:Vector2(0,0) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99143e+06,-4.14666e+06,4.40614e+06)] 1:Vector2(2559,0) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99162e+06,-4.14707e+06,4.40549e+06)] 1:Vector2(2559,1079) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99338e+06,-4.14646e+06,4.40572e+06)] 1:Vector2(0,1079) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.9928e+06,-4.14632e+06,4.40616e+06)] 1:Vector2(640,270) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.9919e+06,-4.14657e+06,4.40599e+06)] 1:Vector2(1920,270) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99202e+06,-4.14684e+06,4.40573e+06)] 1:Vector2(1920,810) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99291e+06,-4.14654e+06,4.40585e+06)] 1:Vector2(640,810) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99335e+06,-4.14637e+06,4.40582e+06)] 2:Vector2(0,0) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.9916e+06,-4.14701e+06,4.40564e+06)] 2:Vector2(2559,0) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99181e+06,-4.14745e+06,4.40503e+06)] 2:Vector2(2559,1079) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99359e+06,-4.14689e+06,4.40531e+06)] 2:Vector2(0,1079) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99295e+06,-4.14662e+06,4.40559e+06)] 2:Vector2(640,270) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99209e+06,-4.14696e+06,4.40553e+06)] 2:Vector2(1920,270) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99219e+06,-4.14718e+06,4.40522e+06)] 2:Vector2(1920,810) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99308e+06,-4.14689e+06,4.40535e+06)] 2:Vector2(640,810) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99303e+06,-4.14632e+06,4.40618e+06)] 3:Vector2(0,0) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.991e+06,-4.14687e+06,4.40602e+06)] 3:Vector2(2559,0) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.9913e+06,-4.14734e+06,4.40519e+06)] 3:Vector2(2559,1079) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99331e+06,-4.14684e+06,4.40542e+06)] 3:Vector2(0,1079) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.9926e+06,-4.14655e+06,4.40589e+06)] 3:Vector2(640,270) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.9916e+06,-4.14678e+06,4.40574e+06)] 3:Vector2(1920,270) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99173e+06,-4.14707e+06,4.40541e+06)] 3:Vector2(1920,810) \n",
      ".\n",
      "Discarding GCP that could not be triangulated: [Control Point: Vector3(-1.99275e+06,-4.14677e+06,4.40545e+06)] 3:Vector2(640,810) \n",
      ".\n",
      "Num GCP       = 32\n",
      "Num valid GCP = 0\n",
      "\n",
      "\n",
      "ERROR: Not enough valid GCPs to apply a transform to the cameras. You may need to use --transform-cameras-using-gcp.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/rdcrlrka/.local/share/mamba/envs/skysat_stereo_snow/bin/camera_solve\", line 832, in <module>\n",
      "    sys.exit(main(sys.argv[1:]))\n",
      "             ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/rdcrlrka/.local/share/mamba/envs/skysat_stereo_snow/bin/camera_solve\", line 825, in main\n",
      "    run_bundle_adjust(options, good_images, good_cameras)\n",
      "  File \"/Users/rdcrlrka/.local/share/mamba/envs/skysat_stereo_snow/bin/camera_solve\", line 557, in run_bundle_adjust\n",
      "    asp_system_utils.generic_run(cmd, verbose)\n",
      "  File \"/Users/rdcrlrka/.local/share/mamba/envs/skysat_stereo_snow/libexec/asp_system_utils.py\", line 517, in generic_run\n",
      "    raise Exception('Failed to run: ' + cmd_str)\n",
      "Exception: Failed to run: bundle_adjust --no-datum /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165725_ssc16d1_0009_basic_analytic.tif.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165753_ssc16d1_0009_basic_analytic.tif.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165753_ssc16d1_0010_basic_analytic.tif.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165822_ssc16d1_0008_basic_analytic.tif.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165725_ssc16d1_0009_basic_analytic.gcp /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165753_ssc16d1_0009_basic_analytic.gcp /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165753_ssc16d1_0010_basic_analytic.gcp /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165822_ssc16d1_0008_basic_analytic.gcp -o /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/asp_ba_out --inline-adjustments -t nadirpinhole --datum wgs84 --transform-cameras-with-shared-gcp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/Users/rdcrlrka/.local/share/mamba/envs/skysat_stereo_snow/bin/camera_solve', '--theia-overrides', '--matching_strategy=CASCADE_HASHING', '--calib-file', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165725_ssc16d1_0009_basic_analytic.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165753_ssc16d1_0009_basic_analytic.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165753_ssc16d1_0010_basic_analytic.tsai /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165822_ssc16d1_0008_basic_analytic.tsai', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165725_ssc16d1_0009_basic_analytic.gcp', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165753_ssc16d1_0009_basic_analytic.gcp', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165753_ssc16d1_0010_basic_analytic.gcp', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camgen_cam_gcp/20240420_165822_ssc16d1_0008_basic_analytic.gcp'], returncode=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cam_solve_folder = os.path.join(out_folder, 'camera_solve')\n",
    "os.makedirs(cam_solve_folder, exist_ok=True)\n",
    "\n",
    "image_list = [\n",
    "    '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif',\n",
    "    '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif',\n",
    "    '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif',\n",
    "    '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif'\n",
    "    ]\n",
    "cam_list = [os.path.join(camgen_folder, os.path.splitext(os.path.basename(x))[0] + '.tsai') for x in image_list]\n",
    "gcp_list = [os.path.join(camgen_folder, os.path.splitext(os.path.basename(x))[0] + '.gcp') for x in image_list]\n",
    "\n",
    "fnc = shutil.which('camera_solve')\n",
    "cmd = [\n",
    "    fnc,\n",
    "    '--theia-overrides', '--matching_strategy=CASCADE_HASHING',\n",
    "    '--calib-file', ' '.join(cam_list),\n",
    "    cam_solve_folder\n",
    "] + image_list + gcp_list\n",
    "\n",
    "subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b92c9aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 80273.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mapproject arguments for first job:\n",
      "['--threads', '1', '--nodata-value', '0', '--ot', 'UInt16', '--tr', '1', '--t_srs', 'EPSG:32611', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/../refdem/MCS_refdem_lidar_COPDEM_merged.tif', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165725_ssc16d1_0009_basic_analytic.tif.tsai', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/20240420_165725_ssc16d1_0009_basic_analytic.tif']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:04<00:00,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving compiled orthorectification log at /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/camera_solve/ortho.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "run_mapproject(\n",
    "    img_list = img_list,\n",
    "    cam_folder = cam_solve_folder,\n",
    "    out_folder = cam_solve_folder,\n",
    "    dem = refdem_file,\n",
    "    t_res = 1,\n",
    "    t_crs = \"EPSG:32611\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4289c",
   "metadata": {},
   "source": [
    "## Initial orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(init_ortho_folder, exist_ok=True)\n",
    "\n",
    "img_list = [x for x in sorted(glob(os.path.join(new_img_folder, '*.tif')))\n",
    "            if not os.path.exists(os.path.join(init_ortho_folder, os.path.basename(x)))]\n",
    "if img_list:\n",
    "    run_mapproject(\n",
    "        img_list = img_list,\n",
    "        cam_folder = camgen_folder,\n",
    "        out_folder = init_ortho_folder,\n",
    "        dem = refdem_file,\n",
    "        t_res = 1,\n",
    "        t_crs = \"EPSG:32611\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830214b",
   "metadata": {},
   "source": [
    "## 1. Triplet bundle adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a337fc61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying stereo image pairs...\n",
      "Requirements:\n",
      "\toverlap >= 10 %\n",
      "\ttrue stereo = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2850/2850 [00:01<00:00, 1831.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of overlapping stereo pairs identified = 387\n",
      "Writing image pairs with full path name.\n",
      "Overlapping stereo pairs saved to file: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/ba_triplets/overlapping_image_pairs.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ba_triplet_folder = os.path.join(out_folder, 'ba_triplets')\n",
    "os.makedirs(ba_triplet_folder, exist_ok=True)\n",
    "\n",
    "# First, identify all overlapping image pairs\n",
    "identify_overlapping_image_pairs(\n",
    "    img_list = sorted(glob(os.path.join(init_ortho_folder, '*.tif'))), \n",
    "    overlap_perc = 10, \n",
    "    utm_epsg = \"EPSG:32611\",\n",
    "    out_folder = ba_triplet_folder,\n",
    "    true_stereo = False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d979953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Identifying triplets\n",
      "Total images: 76\n",
      "After high-overlap grouping: 54 assigned, 22 unassigned.\n",
      "After assignment: 76 assigned (should equal total images).\n",
      "Final groups after splitting: 27\n",
      "Saved 27 triplets to file: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/ba_triplets/bundle_adjust_triplets.json\n",
      "Saved 74 pairs to file: /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/ba_triplets/stereo_pairs.txt\n"
     ]
    }
   ],
   "source": [
    "# Now, identify triplets and within-triplet stereo pairs\n",
    "print('\\nIdentifying triplets')\n",
    "overlap_txt = os.path.join(ba_triplet_folder, 'overlapping_image_pairs.txt')\n",
    "triplets_json, pairs_txt = create_triplets_pairs(overlap_txt, ba_triplet_folder, max_group_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "983cc0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Triplets-BA: 100%|██████████| 1/1 [00:18<00:00, 18.84s/it]\n"
     ]
    }
   ],
   "source": [
    "# BUNDLE ADJUST\n",
    "\n",
    "# Load the triplets file\n",
    "with open(triplets_json, 'r') as f:\n",
    "    triplets = json.load(f)\n",
    "\n",
    "# PICKING UP AFTER CANCELLING - Just run groups without new cameras\n",
    "sub_keys = [g for g in triplets.keys() if len(glob(os.path.join(ba_triplet_folder, g, '*.tsai'))) < 1]\n",
    "triplets = {key: triplets[key] for key in triplets.keys() if key in sub_keys}\n",
    "\n",
    "# Iterate over groups\n",
    "for g in tqdm(list(triplets.keys())[11:12], desc='Triplets-BA'):\n",
    "    # define output folder and prefix\n",
    "    g_folder = os.path.join(ba_triplet_folder, g)\n",
    "    g_prefix = os.path.join(g_folder, 'run')\n",
    "    os.makedirs(g_folder, exist_ok=True)\n",
    "\n",
    "    # subset stereo pairs to relevant images\n",
    "    g_images = triplets[g]['file_names']\n",
    "    pairs = pd.read_csv(pairs_txt, sep=' ', header=0)\n",
    "    g_pairs = pd.concat([\n",
    "        pairs.loc[(pairs['img1'].isin(g_images)) & (pairs['img2'].isin(g_images))],\n",
    "        pairs.loc[(pairs['img2'].isin(g_images)) & (pairs['img1'].isin(g_images))],\n",
    "    ]).drop_duplicates()\n",
    "    g_pairs_txt = os.path.join(g_folder, f\"{g}_overlapping_image_pairs.txt\")\n",
    "    g_pairs.to_csv(g_pairs_txt, header=True, index=False, sep=' ')\n",
    "\n",
    "    # stereo preprocessing\n",
    "    # print('Running stereo preprocessing for dense feature matching')\n",
    "    # run_stereo(\n",
    "    #     stereo_pairs_fn = g_pairs_txt,\n",
    "    #     cam_folder = camgen_folder,\n",
    "    #     dem_file = refdem_file,\n",
    "    #     out_folder = g_folder,\n",
    "    #     stop_point = 1\n",
    "    # )\n",
    "\n",
    "    # # reduce number of matches\n",
    "    # reduce_asp_match_files(\n",
    "    #     match_folder = g_folder,\n",
    "    #     output_folder = g_folder\n",
    "    # )\n",
    "\n",
    "    # get camera and GCP lists\n",
    "    g_cams = [find_matching_camera_file(x, camgen_folder) for x in g_images]\n",
    "\n",
    "    # bundle adjust\n",
    "    args = [\n",
    "        \"--threads\", \"9\",\n",
    "        \"--num-iterations\", \"500\",\n",
    "        \"--num-passes\", \"2\",\n",
    "        \"--inline-adjustments\",\n",
    "        \"--min-matches\", \"4\",\n",
    "        \"--individually-normalize\",\n",
    "        \"--heights-from-dem\", refdem_file,\n",
    "        \"--heights-from-dem-uncertainty\", \"1\",\n",
    "        \"--force-reuse-match-files\",\n",
    "        \"--skip-matching\",\n",
    "        \"-o\", g_prefix\n",
    "        ] + g_images + g_cams\n",
    "\n",
    "    # run bundle adjust\n",
    "    log = run_cmd('parallel_bundle_adjust', args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a181cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 64527.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mapproject arguments for first job:\n",
      "['--threads', '1', '--nodata-value', '0', '--ot', 'UInt16', '--tr', '0.8', '--t_srs', 'EPSG:32611', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/../refdem/MCS_refdem_lidar_COPDEM_merged.tif', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/ba_triplets/group_11/run-20240420_165725_ssc16d1_0009_basic_analytic.tsai', '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/ba_triplets/group_11/20240420_165725_ssc16d1_0009_basic_analytic.tif']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 4/4 [00:21<00:00,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving compiled orthorectification log at /Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/ba_triplets/group_11/ortho.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## TESTING MAPPROJECT AFTER BA TRIPLETS\n",
    "\n",
    "g_folder = os.path.join(ba_triplet_folder, 'group_11')\n",
    "cam_list = glob(os.path.join(g_folder, '*.tsai'))\n",
    "cam_list_base = [os.path.splitext(os.path.basename(x))[0].replace('run-','') for x in cam_list]\n",
    "img_list = sorted(glob(os.path.join(new_img_folder, '*.tif')))\n",
    "img_list = [x for x in img_list if os.path.splitext(os.path.basename(x))[0] in cam_list_base]\n",
    "\n",
    "run_mapproject(\n",
    "    img_list = img_list,\n",
    "    cam_folder = g_folder,\n",
    "    out_folder = g_folder,\n",
    "    dem = refdem_file,\n",
    "    t_res = 0.8,\n",
    "    t_crs = \"EPSG:32611\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e127569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165725_ssc16d1_0009_basic_analytic.tif',\n",
       " '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0009_basic_analytic.tif',\n",
       " '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165753_ssc16d1_0010_basic_analytic.tif',\n",
       " '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/proc_out/single_band_images/20240420_165822_ssc16d1_0008_basic_analytic.tif']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy adjusted cameras to root ba_triplet_folder\n",
    "cam_list = sorted(glob(os.path.join(ba_triplet_folder, '*', '*.tsai')))\n",
    "for cam in tqdm(cam_list):\n",
    "    cam_out = os.path.join(ba_triplet_folder, os.path.basename(cam))\n",
    "    _ = shutil.copy2(cam, cam_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfce6836",
   "metadata": {},
   "source": [
    "## 2. Global bundle adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef776917",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_global_folder = os.path.join(out_folder, 'ba_global')\n",
    "os.makedirs(ba_global_folder, exist_ok=True)\n",
    "\n",
    "# --- Stereo preprocessing ---\n",
    "# Identify overlapping pairs that were not bundle adjusted together\n",
    "overlap = pd.read_csv(overlap_txt, sep=' ', header=0)\n",
    "stereo_pairs = pd.read_csv(pairs_txt, sep=' ', header=0)\n",
    "merged_df = pd.merge(overlap, stereo_pairs, how='left', indicator=True)\n",
    "overlap_filtered = merged_df[merged_df['_merge'] == 'left_only'].drop(columns=['_merge']).reset_index(drop=True)\n",
    "\n",
    "# Subset to overlap > 40%\n",
    "overlap_filtered = overlap_filtered.loc[overlap_filtered['overlap_percent'] > 40].reset_index(drop=True)\n",
    "\n",
    "# Save to file\n",
    "overlap_filtered_txt = os.path.join(ba_global_folder, 'stereo_pairs.txt')\n",
    "overlap_filtered.to_csv(overlap_filtered_txt, sep=' ', header=True, index=False)\n",
    "print('Saved stereo pairs to file:', overlap_filtered_txt)\n",
    "\n",
    "# Run stereo preprocessing\n",
    "ba_global_stereo_folder = os.path.join(ba_global_folder, 'feature_matches')\n",
    "run_stereo(\n",
    "    stereo_pairs_fn = overlap_filtered_txt,\n",
    "    cam_folder = ba_triplet_folder,\n",
    "    dem_file = refdem_file,\n",
    "    out_folder = ba_global_stereo_folder,\n",
    "    stop_point = 1\n",
    ")\n",
    "\n",
    "# --- Reduce number of matches ---\n",
    "reduce_asp_match_files(\n",
    "    match_folder = os.path.join(ba_global_folder, 'feature_matches'),\n",
    "    output_folder = ba_global_folder\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecddd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bundle adjust with one triplet fixed ---\n",
    "cam_list = sorted(glob(os.path.join(ba_triplet_folder, '*.tsai')))\n",
    "cam_list_base = [os.path.splitext(os.path.basename(x))[0].replace('run-','') for x in cam_list]\n",
    "image_list = [os.path.join(init_ortho_folder, x + '.tif') for x in cam_list_base]\n",
    "\n",
    "# Fix one triplet group\n",
    "with open(triplets_json, 'r') as f:\n",
    "    triplets = json.load(f)\n",
    "max_length = max(np.array([triplets[g]['length'] for g in triplets.keys()]))\n",
    "fixed_g = [g for g in triplets.keys() if triplets[g]['length']==max_length][0]\n",
    "print(f'Using triplet {fixed_g} as an anchor.')\n",
    "fixed_images = triplets[fixed_g]['file_names']\n",
    "fixed_image_txt = os.path.join(ba_global_folder, 'fixed_images.txt')\n",
    "with open(fixed_image_txt, 'w') as f:\n",
    "    f.write(' '.join(fixed_images))\n",
    "print('Saved list of fixed images to file:', fixed_image_txt)\n",
    "\n",
    "# Run bundle adjust\n",
    "print('Running global bundle adjust')\n",
    "args = [\n",
    "    \"--threads\", \"9\",\n",
    "    \"--num-iterations\", \"500\",\n",
    "    \"--num-passes\", \"2\",\n",
    "    \"--inline-adjustments\",\n",
    "    \"--min-matches\", \"4\",\n",
    "    \"--individually-normalize\",\n",
    "    \"--fixed-image-list\", fixed_image_txt,\n",
    "    \"--force-reuse-match-files\",\n",
    "    \"--skip-matching\",\n",
    "    \"-o\", os.path.join(ba_global_folder, 'run')\n",
    "    ] + image_list + cam_list\n",
    "\n",
    "# run bundle adjust\n",
    "log = run_cmd('parallel_bundle_adjust', args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165686d",
   "metadata": {},
   "source": [
    "## Intermediate ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interm_ortho_folder = os.path.join(out_folder, 'interm_ortho')\n",
    "os.makedirs(interm_ortho_folder, exist_ok=True)\n",
    "\n",
    "# get only images with successful cameras\n",
    "cam_list = glob(os.path.join(ba_global_folder, '*.tsai'))\n",
    "cam_list_base = [os.path.splitext(os.path.basename(x))[0].replace('run-run-','') for x in cam_list]\n",
    "img_list = sorted(glob(os.path.join(new_img_folder, '*.tif')))\n",
    "img_list = [x for x in img_list if os.path.splitext(os.path.basename(x))[0] in cam_list_base]\n",
    "\n",
    "run_mapproject(\n",
    "    img_list = img_list,\n",
    "    cam_folder = ba_global_folder,\n",
    "    out_folder = interm_ortho_folder,\n",
    "    dem = refdem_file,\n",
    "    t_res = 0.8,\n",
    "    t_crs = \"EPSG:32611\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c40c0",
   "metadata": {},
   "source": [
    "## Final stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930dbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(final_stereo_folder, exist_ok=True)\n",
    "img_list = sorted(glob(os.path.join(interm_ortho_folder, '*.tif')))\n",
    "\n",
    "# Create list of stereo pairs\n",
    "identify_overlapping_image_pairs(\n",
    "    img_list, \n",
    "    overlap_perc = 40, \n",
    "    utm_epsg = \"EPSG:32611\",\n",
    "    out_folder = final_stereo_folder,\n",
    "    )\n",
    "overlap_txt = os.path.join(final_stereo_folder, 'overlapping_image_pairs.txt')\n",
    "\n",
    "# Run stereo\n",
    "run_stereo(\n",
    "    stereo_pairs_fn = overlap_txt,\n",
    "    cam_folder = ba_global_folder,\n",
    "    dem_fn = refdem_file,\n",
    "    out_folder = final_stereo_folder,\n",
    "    correlator_mode = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df7824",
   "metadata": {},
   "source": [
    "## DSM mosaicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b205ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a926455",
   "metadata": {},
   "source": [
    "## DSM coregistration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c60c63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "469043cb",
   "metadata": {},
   "source": [
    "## Final ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d24af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_mapproject(img_list: List[str] = None, \n",
    "#                    cam_folder: str = None, \n",
    "#                    ba_prefix: str = None,\n",
    "#                    out_folder: str = None, \n",
    "#                    dem: str = 'WGS84', \n",
    "#                    t_res: float = None, \n",
    "#                    t_crs: str = None, \n",
    "#                    session: str = None, \n",
    "#                    orthomosaic: bool = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac47bb81",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9b15e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skysat_stereo_snow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
