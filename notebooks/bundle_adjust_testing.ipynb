{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c1ae3eb",
   "metadata": {},
   "source": [
    "# Testing bundle adjust approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d36de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import subprocess\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from p_tqdm import p_map\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "import re\n",
    "import multiprocessing\n",
    "import itertools\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import json\n",
    "import networkx as nx\n",
    "from datetime import datetime\n",
    "\n",
    "# Define inputs\n",
    "data_path = '/Users/rdcrlrka/Research/SkySat-Stereo/study-sites/MCS/20240420/'\n",
    "img_folder = os.path.join(data_path, 'SkySatScene')\n",
    "refdem_file = os.path.join(data_path, '..', 'refdem', 'MCS_refdem_lidar_COPDEM_merged.tif')\n",
    "\n",
    "# Define output folders\n",
    "out_folder = os.path.join(data_path, 'proc_out')\n",
    "os.makedirs(out_folder, exist_ok=True)\n",
    "new_img_folder = os.path.join(out_folder, 'single_band_images')\n",
    "camgen_folder = os.path.join(out_folder, 'camgen_cam_gcp')\n",
    "init_ortho_folder = os.path.join(out_folder, 'init_ortho')\n",
    "ba_triplet_folder = os.path.join(out_folder, 'bundle_adjust_triplets')\n",
    "ba_global_folder = os.path.join(out_folder, 'bundle_adjust_global')\n",
    "final_stereo_folder = os.path.join(out_folder, 'final_stereo')\n",
    "final_ortho_folder = os.path.join(out_folder, 'final_ortho')\n",
    "\n",
    "# Get images\n",
    "img_list = sorted(glob(os.path.join(img_folder, '*analytic.tif')))\n",
    "print(f\"{len(img_list)} images located\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ef0e1",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9aa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cmd(bin: str = None, \n",
    "            args: list = None, **kw) -> str:\n",
    "    binpath = shutil.which(bin)\n",
    "    if binpath.endswith('.py'):\n",
    "        call = ['python', binpath,]\n",
    "    else:\n",
    "        call = [binpath,]\n",
    "    if args is not None: \n",
    "        call.extend(args)\n",
    "    try:\n",
    "        out = subprocess.run(call,check=True,capture_output=True,encoding='UTF-8').stdout\n",
    "    except:\n",
    "        out = \"the command {} failed to run, see corresponding asp log\".format(call)\n",
    "    return out\n",
    "\n",
    "\n",
    "def run_gdal_merge(img_list: str = None,\n",
    "                   mosaic_fn: str = None,\n",
    "                   t_res: float | int = None,\n",
    "                   t_nodata: float | int = 0,\n",
    "                   t_dtype: str = 'UInt16'):\n",
    "    # Make sure output directory exists\n",
    "    if not os.path.exists(os.path.dirname(mosaic_fn)):\n",
    "        os.mkdir(os.path.dirname(mosaic_fn))\n",
    "\n",
    "    # Set up mosaic arguments\n",
    "    mos_args = ['-ot', t_dtype,\n",
    "                '-a_nodata', str(t_nodata)]\n",
    "    if t_res:\n",
    "        mos_args.extend(['-ps', str(t_res), str(t_res)])\n",
    "    mos_args.extend(['-o', mosaic_fn])\n",
    "    mos_args.extend(img_list)\n",
    "\n",
    "    # Run image mosaic\n",
    "    run_cmd('gdal_merge.py', mos_args)\n",
    "\n",
    "\n",
    "def generate_frame_cameras(\n",
    "        img_list = None,\n",
    "        dem_file: str = None, \n",
    "        product_level: str = 'l1b', \n",
    "        gcp_std: float = 1,\n",
    "        out_folder: str = None\n",
    "        ) -> str:\n",
    "    \"\"\"\n",
    "    Generate ASP camera models and GCPs for a list of images using cam_gen.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_list: list\n",
    "        list of image file names\n",
    "    dem_file: str\n",
    "        file name of the reference DEM\n",
    "    product_level: str\n",
    "        product level of the images, either 'l1b' or 'l1a'\n",
    "    out_folder: str\n",
    "        folder where output camera models and GCPs will be saved\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    cam_gen_log: str\n",
    "        file name of the cam_gen log file, which contains information about the number of GCP\n",
    "    \"\"\"\n",
    "    # Make output directory if it doesn't exist\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.mkdir(out_folder)\n",
    "    \n",
    "    cam_list = img_list\n",
    "\n",
    "    # Define output camera and GCP files\n",
    "    frames = [os.path.splitext(os.path.basename(x))[0] for x in img_list] # grab just the image identifier strings\n",
    "    out_cam_list = [os.path.join(out_folder,'{}.tsai'.format(frame)) for frame in frames]\n",
    "    out_gcp_list = [os.path.join(out_folder,'{}.gcp'.format(frame)) for frame in frames]\n",
    "\n",
    "    # Define reference height value where DEM has no data\n",
    "    ht_datum = np.nanmedian(rxr.open_rasterio(dem_file).squeeze().data) \n",
    "\n",
    "    # Determine number of jobs and threads per job\n",
    "    threads = os.cpu_count()\n",
    "    # ncpu, threads_per_job = 4, 3 #setup_parallel_jobs(total_jobs=len(img_list))\n",
    "        \n",
    "    # Iterate over images\n",
    "    log_list = []\n",
    "    for img, cam, out_cam, out_gcp in zip(img_list, cam_list, out_cam_list, out_gcp_list):\n",
    "        # construct arguments\n",
    "        args = [\n",
    "            '--threads', str(threads),\n",
    "            '--focal-length', str(553846.153846),\n",
    "            '--optical-center', str(1280), str(540),\n",
    "            '--height-above-datum', str(ht_datum),\n",
    "            '--gcp-std', str(gcp_std),\n",
    "            '--datum', 'WGS84',\n",
    "            '--reference-dem', dem_file,\n",
    "            '--refine-camera',\n",
    "            '--input-camera', cam,\n",
    "            '-o', out_cam,\n",
    "            '--gcp-file', out_gcp,\n",
    "            img\n",
    "        ]\n",
    "        if product_level=='l1b':\n",
    "            args += ['--pixel-pitch', str(0.8)]\n",
    "        else:\n",
    "            args += ['--pixel-pitch', str(1.0)]\n",
    "\n",
    "        # run command\n",
    "        log = run_cmd('cam_gen', args)\n",
    "        log_list += [log]\n",
    "\n",
    "    # Save compiled cam_gen log\n",
    "    cam_gen_log = os.path.join(out_folder, 'cam_gen.log')\n",
    "    print(\"Saving cam_gen log at {}\".format(cam_gen_log))\n",
    "    with open(cam_gen_log,'w') as f:\n",
    "        for log in log_list:\n",
    "            f.write(log + '\\n')\n",
    "    \n",
    "    # Remove basename from GCP file names\n",
    "    # ASP's cam_gen writes full path for images in the GCP files. This does not play well during bundle adjustment.\n",
    "    # The function returns a consolidated gcp file with all images paths only containing basenames so that bundle adjustment can roll along\n",
    "    # See ASP's gcp logic here: https://stereopipeline.readthedocs.io/en/latest/tools/bundle_adjust.html#bagcp\n",
    "    print(\"Writing GCPs with dirname removed\")  \n",
    "    def clean_img_in_gcp(row):\n",
    "        return os.path.basename(row[7])\n",
    "    for out_gcp in tqdm(out_gcp_list):\n",
    "        df = pd.read_csv(out_gcp, header=None,delimiter=r\"\\s+\")\n",
    "        df[7] = df.apply(clean_img_in_gcp, axis=1)\n",
    "        df[0] = np.arange(len(df))\n",
    "        out_fn = os.path.join(out_folder, os.path.basename(out_gcp).replace('.gcp', '_clean.gcp'))\n",
    "        df.to_csv(out_fn, sep=' ', index=False, header=False)\n",
    "\n",
    "    return cam_gen_log\n",
    "\n",
    "\n",
    "def calculate_baseline_to_height_ratio(\n",
    "        img1: str = None, \n",
    "        img2: str = None, \n",
    "        utm_epsg: str = None\n",
    "        ) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the baseline to height ratio for a pair of images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img1: str\n",
    "        file name of the first image\n",
    "    img2: str\n",
    "        file name of the second image\n",
    "    utm_epsg: str\n",
    "        EPSG code for the optimal UTM zone, e.g. \"EPSG:32601\"\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    b_h_ratio: float\n",
    "        baseline to height ratio, where baseline is the distance between camera centers and height is the average height of the two images\n",
    "    \"\"\"\n",
    "    # iterate over images\n",
    "    cams_list, h_list = [], []\n",
    "    for img in [img1, img2]:\n",
    "        # get camera center coordinates and heights\n",
    "        with rio.open(img) as src:\n",
    "            h = src.rpcs.height_off\n",
    "            lat = src.rpcs.lat_off\n",
    "            lon = src.rpcs.long_off\n",
    "        # reproject to UTM for distance calculations\n",
    "        gdf = gpd.GeoDataFrame(index=[0], geometry=[Point(lon, lat)], crs=\"EPSG:4326\")\n",
    "        gdf = gdf.to_crs(utm_epsg)\n",
    "        x = gdf.geometry[0].coords.xy[0][0]\n",
    "        y = gdf.geometry[0].coords.xy[0][0]\n",
    "        # save in arrays\n",
    "        cams_list += [[x,y]]\n",
    "        h_list += [h]\n",
    "    # calculate baseline\n",
    "    diff = np.array(cams_list[0]) - np.array(cams_list[1])\n",
    "    b = np.linalg.norm(diff)\n",
    "    h_mean = np.nanmean(np.array(h_list))\n",
    "    # calculate B/H ratio\n",
    "    return float(b / h_mean)\n",
    "\n",
    "\n",
    "def rpc_image_latlon_bounds(\n",
    "        img_fn: str = None, \n",
    "        height: float = 0.0\n",
    "        ) -> tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Get bounding box (min lon, min lat, max lon, max lat) for image with RPC metadata.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_fn: str\n",
    "        Path to image file with RPCs.\n",
    "    height: float\n",
    "        Ground height in meters used for projection.\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    tuple: [min_lon, min_lat, max_lon, max_lat]\n",
    "    \"\"\"\n",
    "    with rio.open(img_fn) as src:\n",
    "        if not src.rpcs:\n",
    "            raise ValueError(\"Image does not contain RPC metadata.\")\n",
    "\n",
    "        transformer = rio.transform.RPCTransformer(src.rpcs)\n",
    "\n",
    "        width = src.width\n",
    "        height_px = src.height\n",
    "\n",
    "        # Image corners (col, row)\n",
    "        pixel_coords = [\n",
    "            (0, 0),                    # top-left\n",
    "            (width - 1, 0),            # top-right\n",
    "            (width - 1, height_px - 1),# bottom-right\n",
    "            (0, height_px - 1)         # bottom-left\n",
    "        ]\n",
    "\n",
    "        cols, rows = zip(*pixel_coords)\n",
    "        zs = [height] * 4\n",
    "\n",
    "        lons, lats = transformer.xy(cols, rows, zs)\n",
    "\n",
    "        min_lon = float(np.min(lons))\n",
    "        max_lon = float(np.max(lons))\n",
    "        min_lat = float(np.min(lats))\n",
    "        max_lat = float(np.max(lats))\n",
    "\n",
    "        return min_lon, min_lat, max_lon, max_lat\n",
    "    \n",
    "\n",
    "def find_matching_camera_file(\n",
    "        image_fn: str = None, \n",
    "        cam_folder: str = None\n",
    "        ) -> str:\n",
    "    \"\"\"\n",
    "    Find camera file matching the image file's unique identifier.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image_fn: str\n",
    "        file name of the image\n",
    "    cam_folder: str\n",
    "        folder containing camera files\n",
    "    Returns\n",
    "    ----------\n",
    "    matched_fn: str\n",
    "        file name of the matching camera file\n",
    "    \"\"\"\n",
    "    # Get the identifying string from the image file\n",
    "    # File naming convention SkySatScenes (https://developers.planet.com/docs/data/skysat/): \n",
    "    # <acquisition date>_<acquisition time>_<satellite_id><camera_id>_<frame_id>_<bandProduct>\n",
    "    match = re.search(r\"\\d{8}_\\d{6}_[a-zA-Z0-9]+_\\d{4}\", image_fn)\n",
    "    if match:\n",
    "        identifier = match.group(0)\n",
    "    else:\n",
    "        identifier = None\n",
    "    if not identifier:\n",
    "        raise ValueError(f\"Could not extract identifier from image: {image_fn}\")\n",
    "\n",
    "    # Find matching camera file(s)\n",
    "    cam_list = (glob(os.path.join(cam_folder, \"*.tsai\")) \n",
    "                + glob(os.path.join(cam_folder, '*.TXT')))\n",
    "    matched_fns = [f for f in cam_list if identifier in f]\n",
    "    # ideally, only one match, otherwise it's ambiguous\n",
    "    if len(matched_fns) == 0:\n",
    "        raise ValueError(f\"No matching camera file found for image: {image_fn}\")\n",
    "    elif len(matched_fns) > 1:\n",
    "        print(f\"Multiple matching camera files found for image: {image_fn}. \" \n",
    "              \"Returning the first one.\")\n",
    "        \n",
    "    return matched_fns[0]\n",
    "\n",
    "\n",
    "def setup_parallel_jobs(\n",
    "        total_jobs: int = None,\n",
    "        verbose: bool = True\n",
    "        ) -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Determine the number of parallel jobs to run and threads per job.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    total_jobs: int\n",
    "        The total number of jobs to run (e.g., number of stereo pairs).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    njobs: int\n",
    "        Number of parallel processes to run.\n",
    "    threads_per_job: int\n",
    "        Number of threads to allocate per process.\n",
    "    \"\"\"\n",
    "    total_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "    if total_jobs <= 1:\n",
    "        njobs = 1\n",
    "    elif total_jobs <= 10:\n",
    "        njobs = min(2, total_jobs)\n",
    "    elif total_jobs <= 100:\n",
    "        njobs = min(4, total_jobs)\n",
    "    else:\n",
    "        njobs = min(4, total_jobs)\n",
    "\n",
    "    threads_per_job = max(1, total_cpus // njobs)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Will run {total_jobs} jobs across {njobs} CPU with {threads_per_job} threads per CPU\")\n",
    "\n",
    "    return njobs, threads_per_job\n",
    "\n",
    "\n",
    "def run_mapproject(\n",
    "        img_list: str = None, \n",
    "        cam_folder: str = None, \n",
    "        ba_prefix: str = None,\n",
    "        out_folder: str = None, \n",
    "        dem: str = 'WGS84', \n",
    "        t_res: float = None, \n",
    "        t_crs: str = None, \n",
    "        session: str = None, \n",
    "        orthomosaic: bool = False\n",
    "        ) -> None:\n",
    "    \"\"\"\n",
    "    Mapproject images onto a reference DEM and optionally, create median mosaic of mapprojected images. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_list: list of str\n",
    "        list of image file names\n",
    "    cam_folder: str\n",
    "        folder containing camera files\n",
    "    ba_prefix: str\n",
    "        bundle adjust prefix used to grab cameras or adjustments\n",
    "    out_folder: str\n",
    "        path to the folder where mapprojected images and cameras will be saved\n",
    "    dem: str (default=\"WGS84\")\n",
    "        reference DEM used for mapprojection. If None, will use the WGS84 datum.\n",
    "    t_res: float | str\n",
    "        target spatial resolution of the mapprojected images (meters)\n",
    "    t_crs: str\n",
    "        target coordinate reference system of the mapprojected images (e.g., \"EPSG:4326\")\n",
    "    session: str\n",
    "        ASP session type (e.g., \"pinhole\"). Usually, ASP can determine this automatically based on the inputs. \n",
    "    orthomosaic: bool\n",
    "        whether to create a median mosaic of the mapprojected images, along with count, NMAD, weighted average, \n",
    "        and mosaics from different stereo views\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    # Set up image specific arguments: output prefixes and cameras\n",
    "    frames_list = [os.path.splitext(os.path.basename(img))[0] for img in img_list]\n",
    "    out_list = [os.path.join(out_folder, img + '.tif') for img in frames_list]\n",
    "    cam_list = [find_matching_camera_file(img, cam_folder) for img in img_list]\n",
    "\n",
    "    # Determine number of threads to use per job\n",
    "    # ncpu, threads_per_job = setup_parallel_jobs(total_jobs=len(img_list))\n",
    "    # Mapproject is automatically splitting images into a single tile, \n",
    "    # so only one threads is needed for each image job\n",
    "    ncpu, threads_per_job = 12, 1\n",
    "\n",
    "    # Set up mapproject arguments\n",
    "    map_opts = [\n",
    "        '--threads', str(threads_per_job),\n",
    "        # limit to integer values, with 0 as no-data\n",
    "        '--nodata-value', '0',\n",
    "        '--ot', 'UInt16'\n",
    "        ]\n",
    "    if t_res:\n",
    "        map_opts += ['--tr', str(t_res)]\n",
    "    if t_crs:\n",
    "        map_opts += ['--t_srs', str(t_crs)]\n",
    "    if session:\n",
    "        map_opts += ['--session', session]\n",
    "    if ba_prefix:\n",
    "        map_opts += ['--bundle-adjust-prefix', ba_prefix]\n",
    "\n",
    "    # Set up jobs\n",
    "    jobs_list = []\n",
    "    for img, cam, out in tqdm(list(zip(img_list, cam_list, out_list))):\n",
    "        job = map_opts + [dem, img, cam, out]\n",
    "        jobs_list += [job]\n",
    "    print('\\nmapproject arguments for first job:')\n",
    "    print(jobs_list[0])\n",
    "    \n",
    "    # Run in parallel\n",
    "    log_list = p_map(run_cmd, ['mapproject']*len(jobs_list), jobs_list, num_cpus=ncpu)\n",
    "    \n",
    "    # Save compiled ortho log\n",
    "    ortho_log = os.path.join(out_folder, 'ortho.log')\n",
    "    print(\"Saving compiled orthorectification log at {}\".format(ortho_log))\n",
    "    with open(ortho_log,'w') as f:\n",
    "        for log in log_list:\n",
    "            f.write(log + '\\n')\n",
    "    \n",
    "    # Create orthomosaic\n",
    "    if orthomosaic:\n",
    "        print(\"\\nCreating orthomosaic\")\n",
    "        # get unique image datetimes\n",
    "        dt_list = list(set(sorted(['_'.join(os.path.basename(im).split('_')[0:2]) for im in out_list])))\n",
    "\n",
    "        # define mosaic prefix containing timestamps of inputs\n",
    "        mos_prefix = '__'.join(dt_list)\n",
    "\n",
    "        # define output filenames\n",
    "        mosaic_fn = os.path.join(out_folder, f'{mos_prefix}_orthomosaic.tif')\n",
    "\n",
    "        run_gdal_merge(\n",
    "            img_list=out_list, \n",
    "            mosaic_fn = mosaic_fn,\n",
    "            t_res = t_res\n",
    "            )\n",
    "\n",
    "\n",
    "def identify_overlapping_image_pairs(\n",
    "        img_list: str = None, \n",
    "        overlap_perc: float = 10, \n",
    "        bh_ratio_range: tuple = None,\n",
    "        true_stereo: bool = True,\n",
    "        utm_epsg: str = None,\n",
    "        out_folder: str = None,\n",
    "        write_basename: bool = False\n",
    "        )-> None:\n",
    "    # Make sure out_folder exists\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    # Get image bounds polygons\n",
    "    def get_image_polygon(img_fn):\n",
    "        # if no CRS, image is likely raw, ungeoregistered. Estimate using RPC.\n",
    "        crs = rxr.open_rasterio(img_fn).rio.crs\n",
    "        if not crs:\n",
    "            min_x, min_y, max_x, max_y = rpc_image_latlon_bounds(img_fn)\n",
    "            crs = \"EPSG:4326\"\n",
    "        # otherwise, use the embedded image bounds.\n",
    "        else:\n",
    "            min_x, min_y, max_x, max_y = rxr.open_rasterio(img_fn).rio.bounds()\n",
    "        # convert bounds to polygon\n",
    "        bounds_poly = Polygon([[min_x, min_y], [max_x, min_y],\n",
    "                                [max_x, max_y], [min_x, max_y],\n",
    "                                [min_x, min_y]])\n",
    "        # make sure bounds are in UTM projection\n",
    "        bounds_gdf = gpd.GeoDataFrame(index=[0], geometry=[bounds_poly], crs=crs)\n",
    "        bounds_gdf = bounds_gdf.to_crs(utm_epsg)\n",
    "\n",
    "        return bounds_gdf.geometry[0]\n",
    "    polygons = {img: get_image_polygon(img) for img in img_list}\n",
    "    \n",
    "    # Compare all unique pairs\n",
    "    print('Identifying stereo image pairs...')\n",
    "    print(f'Requirements:')\n",
    "    print(f'\\toverlap >= {overlap_perc} %')\n",
    "    if bh_ratio_range:\n",
    "        print(f'\\tbaseline to height ratio = {bh_ratio_range[0]} to {bh_ratio_range[1]}')\n",
    "    print(f'\\ttrue stereo = {true_stereo}')\n",
    "    overlapping_pairs = []\n",
    "    overlap_ratios = []\n",
    "    bh_ratios = []\n",
    "    # number of combos for progress bar\n",
    "    n = len(img_list)\n",
    "    total = n * (n - 1) // 2\n",
    "    for img1, img2 in tqdm(itertools.combinations(img_list, 2), total=total):\n",
    "        poly1 = polygons[img1]\n",
    "        poly2 = polygons[img2]\n",
    "\n",
    "        intersection = poly1.intersection(poly2)\n",
    "        if not intersection.is_empty:\n",
    "            area1 = poly1.area\n",
    "            area2 = poly2.area\n",
    "            overlap_percent = intersection.area / min(area1, area2) * 100\n",
    "            if overlap_percent >= overlap_perc:\n",
    "                # check for B/H ratio thresholds if specified\n",
    "                bh_ratio = calculate_baseline_to_height_ratio(img1, img2, utm_epsg)\n",
    "                if bh_ratio_range:\n",
    "                    if (bh_ratio < bh_ratio_range[0]) | (bh_ratio > bh_ratio_range[1]):\n",
    "                        continue\n",
    "                \n",
    "                # check for true stereo if specified - datetimes must be different\n",
    "                dt1 = '_'.join(os.path.basename(img1).split('_')[0:2])\n",
    "                dt2 = '_'.join(os.path.basename(img2).split('_')[0:2])\n",
    "                if true_stereo & (dt1==dt2):\n",
    "                    continue\n",
    "\n",
    "                bh_ratios += [bh_ratio]\n",
    "                overlapping_pairs += [(img1, img2)]\n",
    "                overlap_ratios += [overlap_percent]\n",
    "    print('Number of overlapping stereo pairs identified =', len(overlap_ratios))\n",
    "                    \n",
    "    # Write to file\n",
    "    out_fn = os.path.join(out_folder, 'overlapping_image_pairs.txt')\n",
    "    # add the header\n",
    "    with open(out_fn, 'w') as f:\n",
    "        f.write(f\"img1 img2 datetime_identifier overlap_percent bh_ratio\\n\")\n",
    "    # iterate over pairs\n",
    "    for i, (img1, img2) in enumerate(overlapping_pairs):\n",
    "        date1, time1 = os.path.basename(img1).split('_')[0:2]\n",
    "        date2, time2 = os.path.basename(img2).split('_')[0:2]\n",
    "        dt_text = date1 + '_' + time1 + '__' + date2 + '_' + time2\n",
    "        with open(out_fn, 'a') as f:\n",
    "            if write_basename:\n",
    "                if i==0:\n",
    "                    print('\\nWriting image pairs with basename only.')\n",
    "                f.write(f\"{os.path.basename(img1)} {os.path.basename(img2)} {dt_text} {overlap_ratios[i]} {bh_ratios[i]}\\n\")\n",
    "            else:\n",
    "                if i==0:\n",
    "                    print('Writing image pairs with full path name.')\n",
    "                f.write(f\"{img1} {img2} {dt_text} {overlap_ratios[i]} {bh_ratios[i]}\\n\")\n",
    "\n",
    "    print('Overlapping stereo pairs saved to file:', out_fn)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def create_triplets_pairs(overlap_txt, output_folder, high_overlap_thresh=65, max_group_size=4):\n",
    "    \"\"\"\n",
    "    Create overlapping triplet groups (for bundle adjust) and stereo pairs \n",
    "    from overlapping image data. Ensures each image belongs to exactly one triplet.\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load overlap data\n",
    "    df = pd.read_csv(overlap_txt, sep=' ', header=0)\n",
    "\n",
    "    # Initialize tracking\n",
    "    groups_dict = {}\n",
    "    assigned = set()\n",
    "    image_list = set(df[['img1', 'img2']].values.flatten())\n",
    "    unassigned = set(image_list)\n",
    "\n",
    "    print(f\"Total images: {len(image_list)}\")\n",
    "\n",
    "    # --- Start with high-overlap pairs ---\n",
    "    df_max = df[df['overlap_percent'] > high_overlap_thresh].sort_values(by='overlap_percent', ascending=False)\n",
    "\n",
    "    i = 0\n",
    "    for _, row in df_max.iterrows():\n",
    "        img1, img2 = row['img1'], row['img2']\n",
    "        if img1 in assigned or img2 in assigned:\n",
    "            continue  # skip already used\n",
    "\n",
    "        # Find a third image overlapping strongly with either img1 or img2\n",
    "        df_third = df[\n",
    "            ((df['img1'].isin([img1, img2])) | (df['img2'].isin([img1, img2])))\n",
    "            & (~df['img1'].isin([img1, img2]))\n",
    "            & (~df['img2'].isin([img1, img2]))\n",
    "        ].sort_values(by='overlap_percent', ascending=False)\n",
    "\n",
    "        if not df_third.empty:\n",
    "            row3 = df_third.iloc[0]\n",
    "            img3 = row3['img1'] if row3['img1'] not in [img1, img2] else row3['img2']\n",
    "            group_imgs = [img1, img2, img3]\n",
    "        else:\n",
    "            group_imgs = [img1, img2]\n",
    "\n",
    "        # Save group\n",
    "        df_group = df[(df['img1'].isin(group_imgs)) & (df['img2'].isin(group_imgs))]\n",
    "        groups_dict[f'group_{i}'] = {\n",
    "            'file_names': group_imgs,\n",
    "            'length': len(group_imgs),\n",
    "            'overlap_percent_mean': float(df_group['overlap_percent'].mean()),\n",
    "            'bh_ratio_mean': float(df_group['bh_ratio'].mean())\n",
    "        }\n",
    "\n",
    "        assigned.update(group_imgs)\n",
    "        unassigned = image_list - assigned\n",
    "        i += 1\n",
    "\n",
    "    print(f\"After high-overlap grouping: {len(assigned)} assigned, {len(unassigned)} unassigned.\")\n",
    "\n",
    "    # --- Assign remaining images to best overlapping group ---\n",
    "    while unassigned:\n",
    "        ref_img = next(iter(unassigned))\n",
    "        df_img = df[(df['img1'] == ref_img) | (df['img2'] == ref_img)]\n",
    "        if df_img.empty:\n",
    "            # no overlaps — make its own group\n",
    "            groups_dict[f'group_{i}'] = {\n",
    "                'file_names': [ref_img],\n",
    "                'length': 1,\n",
    "                'overlap_percent_mean': 0.0,\n",
    "                'bh_ratio_mean': 0.0\n",
    "            }\n",
    "            assigned.add(ref_img)\n",
    "            unassigned = image_list - assigned\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # find the best overlapping assigned image\n",
    "        df_img_sorted = df_img.sort_values(by='overlap_percent', ascending=False)\n",
    "        for _, row in df_img_sorted.iterrows():\n",
    "            img_best = row['img1'] if row['img1'] != ref_img else row['img2']\n",
    "            found_group = None\n",
    "            for g, ginfo in groups_dict.items():\n",
    "                if img_best in ginfo['file_names']:\n",
    "                    found_group = g\n",
    "                    break\n",
    "            if found_group:\n",
    "                ginfo = groups_dict[found_group]\n",
    "                if ref_img not in ginfo['file_names']:\n",
    "                    ginfo['file_names'].append(ref_img)\n",
    "                    ginfo['length'] += 1\n",
    "                assigned.add(ref_img)\n",
    "                break\n",
    "        else:\n",
    "            # no overlapping assigned image — make a new pair\n",
    "            img_best = df_img_sorted.iloc[0]['img1'] if df_img_sorted.iloc[0]['img1'] != ref_img else df_img_sorted.iloc[0]['img2']\n",
    "            groups_dict[f'group_{i}'] = {\n",
    "                'file_names': [ref_img, img_best],\n",
    "                'length': 2,\n",
    "                'overlap_percent_mean': float(df_img_sorted.iloc[0]['overlap_percent']),\n",
    "                'bh_ratio_mean': float(df_img_sorted.iloc[0]['bh_ratio'])\n",
    "            }\n",
    "            assigned.update([ref_img, img_best])\n",
    "        unassigned = image_list - assigned\n",
    "        i += 1\n",
    "\n",
    "    print(f\"After assignment: {len(assigned)} assigned (should equal total images).\")\n",
    "\n",
    "    # --- Split large groups with overlap-preserving subgroups ---\n",
    "    new_groups_dict = {}\n",
    "    new_group_idx = 0\n",
    "\n",
    "    for _, ginfo in groups_dict.items():\n",
    "        files = ginfo['file_names']\n",
    "\n",
    "        if len(files) <= max_group_size:\n",
    "            new_groups_dict[f'group_{new_group_idx}'] = ginfo\n",
    "            new_group_idx += 1\n",
    "            continue\n",
    "\n",
    "        # Build overlap graph among images in this group\n",
    "        G = nx.Graph()\n",
    "        df_sub = df[(df['img1'].isin(files)) & (df['img2'].isin(files))]\n",
    "        for _, row in df_sub.iterrows():\n",
    "            G.add_edge(row['img1'], row['img2'], weight=row['overlap_percent'])\n",
    "\n",
    "        remaining = set(files)\n",
    "        while remaining:\n",
    "            if len(remaining) <= max_group_size:\n",
    "                sub_group = list(remaining)\n",
    "                remaining.clear()\n",
    "            else:\n",
    "                # start from node with highest degree (most connections)\n",
    "                node = max(remaining, key=lambda n: G.degree(n))\n",
    "                neighbors = sorted(\n",
    "                    [nbr for nbr in G.neighbors(node) if nbr in remaining],\n",
    "                    key=lambda n: G[node][n]['weight'],\n",
    "                    reverse=True\n",
    "                )\n",
    "                sub_group = [node] + neighbors[:max_group_size - 1]\n",
    "                remaining -= set(sub_group)\n",
    "                # overlap last node to maintain connection\n",
    "                if sub_group[-1] not in remaining:\n",
    "                    remaining.add(sub_group[-1])\n",
    "\n",
    "            # Save subgroup\n",
    "            df_group = df[(df['img1'].isin(sub_group)) | (df['img2'].isin(sub_group))]\n",
    "            new_groups_dict[f'group_{new_group_idx}'] = {\n",
    "                'file_names': sub_group,\n",
    "                'length': len(sub_group),\n",
    "                'overlap_percent_mean': float(df_group['overlap_percent'].mean()),\n",
    "                'bh_ratio_mean': float(df_group['bh_ratio'].mean())\n",
    "            }\n",
    "            new_group_idx += 1\n",
    "\n",
    "    print(f\"Final groups after splitting: {len(new_groups_dict)}\")\n",
    "\n",
    "    # --- Generate stereo pairs from triplets ---\n",
    "    stereo_pairs_list = []\n",
    "    for _, ginfo in new_groups_dict.items():\n",
    "        imgs = ginfo['file_names']\n",
    "        for pair in itertools.combinations(imgs, 2):\n",
    "            # check both orientations in df\n",
    "            mask = (\n",
    "                ((df['img1'] == pair[0]) & (df['img2'] == pair[1])) |\n",
    "                ((df['img1'] == pair[1]) & (df['img2'] == pair[0]))\n",
    "            )\n",
    "            df_pair = df.loc[mask]\n",
    "            # only add if not empty\n",
    "            if not df_pair.empty:\n",
    "                stereo_pairs_list.append(df_pair)\n",
    "    stereo_pairs = pd.concat(stereo_pairs_list, ignore_index=True).drop_duplicates(subset=['img1', 'img2'])\n",
    "\n",
    "    # --- Save outputs ---\n",
    "    # Save triplets as JSON to account to potentially different-sized groups\n",
    "    triplets_json = os.path.join(output_folder, 'bundle_adjust_triplets.json')\n",
    "    with open(triplets_json, 'w') as f:\n",
    "        json.dump(new_groups_dict, f, indent=2)\n",
    "    print(f\"Saved {len(new_groups_dict)} triplets to file:\", triplets_json)\n",
    "\n",
    "    # Save pairs as TXT for easier reading\n",
    "    stereo_pairs_txt = os.path.join(output_folder, 'stereo_pairs.txt')\n",
    "    stereo_pairs.to_csv(stereo_pairs_txt, sep=' ', header=True, index=False)\n",
    "    print(f\"Saved {len(stereo_pairs)} pairs to file:\", stereo_pairs_txt)\n",
    "\n",
    "    return triplets_json, stereo_pairs_txt\n",
    "\n",
    "\n",
    "def get_stereo_opts(\n",
    "        session: str = None, \n",
    "        threads: int = None, \n",
    "        texture: str = 'normal', \n",
    "        stop_point: int = -1, \n",
    "        unalign_disparity: bool = False\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Get the stereo options for the ASP parallel_stereo command.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    session: str (default=None)\n",
    "        The session type to use for stereo matching. Options include 'rpc', 'pinhole', etc. \n",
    "        ASP can often figure this out automatically. \n",
    "    threads: int (default=None)\n",
    "        Number of threads to use for parallel processing. If None, will automatically determine based on CPU count.\n",
    "    texture: str (default='normal')\n",
    "        This is used for determining the correlation and refinement kernel. Options = \"low\", \"normal\".\n",
    "    stop_point: int (default=-1)\n",
    "        Stopping point for stereo processing. Set to -1 to run all steps. Useful if only creating feature matches \n",
    "        or running image correlation, for example. See the ASP docs on stereo entry points for more information: \n",
    "        https://stereopipeline.readthedocs.io/en/latest/tools/parallel_stereo.html#entrypoints\n",
    "    unalign_disparity: bool (default=False)\n",
    "        Whether to generate disparity maps without alignment. This can be used for debugging or testing purposes.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    stereo_opt: list\n",
    "        A list of command line options for the ASP parallel_stereo command.\n",
    "    \"\"\"\n",
    "    stereo_opts = []\n",
    "    # session_args\n",
    "    if session:\n",
    "        stereo_opts.extend(['-t', session])\n",
    "    stereo_opts.extend(['--threads-multiprocess', str(threads)])\n",
    "    stereo_opts.extend(['--threads-singleprocess', str(threads)])\n",
    "    # stereo_pprc args : This is for preprocessing (adjusting image dynamic range, \n",
    "    # alignment using ip matches, etc.)\n",
    "    stereo_opts.extend(['--individually-normalize'])\n",
    "    stereo_opts.extend(['--ip-per-tile', '8000'])\n",
    "    stereo_opts.extend(['--ip-num-ransac-iterations','2000'])\n",
    "    stereo_opts.extend(['--force-reuse-match-files'])\n",
    "    stereo_opts.extend(['--skip-rough-homography'])\n",
    "    stereo_opts.extend(['--alignment-method', 'Affineepipolar'])\n",
    "    # mask out completely feature less area using a std filter, to avoid gross MGM errors\n",
    "    # this is experimental and needs more testing\n",
    "    stereo_opts.extend(['--stddev-mask-thresh', '0.5'])\n",
    "    stereo_opts.extend(['--stddev-mask-kernel', '-1'])\n",
    "    # stereo_corr_args\n",
    "    stereo_opts.extend(['--stereo-algorithm', 'asp_mgm'])\n",
    "    # correlation kernel size depends on the texture\n",
    "    if texture=='low':\n",
    "        stereo_opts.extend(['--corr-kernel', '9', '9'])\n",
    "    elif texture=='normal':\n",
    "        stereo_opts.extend(['--corr-kernel', '7', '7'])\n",
    "    stereo_opts.extend(['--corr-tile-size', '1024'])\n",
    "    stereo_opts.extend(['--cost-mode', '4'])\n",
    "    stereo_opts.extend(['--corr-max-levels', '5'])\n",
    "    # stereo_rfne_args:\n",
    "    stereo_opts.extend(['--subpixel-mode', '9'])\n",
    "    if texture=='low':\n",
    "        stereo_opts.extend(['--subpixel-kernel', '21', '21'])\n",
    "    elif texture=='normal':\n",
    "        stereo_opts.extend(['--subpixel-kernel', '15', '15'])\n",
    "    stereo_opts.extend(['--xcorr-threshold', '2'])\n",
    "    stereo_opts.extend(['--num-matches-from-disparity', '10000'])\n",
    "    # add stopping point if specified\n",
    "    if stop_point!=-1:\n",
    "        stereo_opts.extend(['--stop-point', str(stop_point)])\n",
    "    # get the disparity map without any alignment\n",
    "    if unalign_disparity:\n",
    "        stereo_opts.extend(['--unalign-disparity'])\n",
    "    \n",
    "    return stereo_opts\n",
    "\n",
    "\n",
    "def run_stereo(\n",
    "        stereo_pairs_fn: str = None, \n",
    "        cam_folder: str = None, \n",
    "        dem_file: str = None,\n",
    "        out_folder: str = None, \n",
    "        session: str = None,\n",
    "        texture: str = 'normal', \n",
    "        stop_point: int = -1,\n",
    "        verbose: bool = True\n",
    "        ) -> None:\n",
    "    \"\"\"\n",
    "    Execute stereo matching for SkySat images using the ASP parallel_stereo command.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    stereo_pairs_fn: str (default=None)\n",
    "        Path to the text file containing overlapping image pairs.\n",
    "    cam_folder: str (default=None)\n",
    "        Path to the folder containing camera files. Required if using 'pinhole' session.\n",
    "    dem_file: str (default=None)\n",
    "\n",
    "    out_folder: str\n",
    "        Path to the folder where the output stereo results will be saved.\n",
    "    session: str (default=None)\n",
    "        The session type to use for stereo matching. Options include 'rpc', 'pinhole', etc. ASP can often figure this out automatically.\n",
    "    texture: str (default='normal')\n",
    "        How much relative texture there is in your images. This is used for determining the correlation and refinement kernel. \n",
    "        Options = \"low\", \"normal\". For example, a flat, snowy landscape likely has \"low\" texture. \n",
    "    stop_point: int\n",
    "\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Check if output folder exists\n",
    "    if not os.path.exists(out_folder):\n",
    "        os.makedirs(out_folder)\n",
    "    \n",
    "    # Load the stereo pairs\n",
    "    stereo_pairs_df = pd.read_csv(stereo_pairs_fn, sep=' ', header=0)\n",
    "\n",
    "    # Determine number of CPUs for parallelization and threads per job\n",
    "    ncpu, threads_per_job = setup_parallel_jobs(total_jobs=len(stereo_pairs_df), verbose=verbose)\n",
    "    \n",
    "    # Define stereo arguments\n",
    "    stereo_opts = get_stereo_opts(\n",
    "        session=session, \n",
    "        threads=threads_per_job, \n",
    "        texture=texture, \n",
    "        stop_point=stop_point\n",
    "        )\n",
    "    \n",
    "    # Create jobs list for each stereo pair\n",
    "    job_list = []\n",
    "    for _, row in stereo_pairs_df.iterrows():\n",
    "        # Determine output folder for stereo job\n",
    "        IMG1 = os.path.splitext(os.path.basename(row['img1']))[0]\n",
    "        IMG2 = os.path.splitext(os.path.basename(row['img2']))[0]\n",
    "        out_prefix = os.path.join(out_folder, row['datetime_identifier'], IMG1 + '__' + IMG2, 'run')  \n",
    "\n",
    "        # Construct the stereo job\n",
    "        if cam_folder:\n",
    "            # Use the camera files if provided\n",
    "            cam1 = find_matching_camera_file(row['img1'], cam_folder)\n",
    "            cam2 = find_matching_camera_file(row['img2'], cam_folder)\n",
    "            job = stereo_opts + [row['img1'], cam1, row['img2'], cam2, out_prefix]\n",
    "        else:\n",
    "            # Otherwise, use the images directly\n",
    "            stereo_args = [row['img1'], row['img2'], out_prefix]\n",
    "            job = stereo_opts + stereo_args\n",
    "        # add DEM last\n",
    "        if dem_file:\n",
    "            job += [dem_file]\n",
    "\n",
    "        # Add job to list of jobs\n",
    "        job_list.append(job)\n",
    "\n",
    "    if verbose:\n",
    "        print('stereo arguments for first job:')\n",
    "        print(job_list[0])\n",
    "    \n",
    "    # Run the jobs in parallel\n",
    "    stereo_logs = p_map(run_cmd, ['parallel_stereo']*len(job_list), job_list, num_cpus=ncpu)\n",
    "\n",
    "    # Save the consolidated log\n",
    "    stereo_log_fn = os.path.join(out_folder, 'stereo_log.log')\n",
    "    with open(stereo_log_fn, 'w') as f:\n",
    "        for log in stereo_logs:\n",
    "            f.write(log + '\\n')\n",
    "    if verbose:\n",
    "        print(\"Consolidated stereo log saved at {}\".format(stereo_log_fn))\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def copy_match_files(matches_folder, image_files, output_prefix, verbose=True):\n",
    "    # get match files from output_folder and any subfolders\n",
    "    match_list = sorted(glob(os.path.join(matches_folder, '*.match')))\n",
    "    if not match_list:\n",
    "        match_list = sorted(glob(os.path.join(matches_folder, '*', '*.match')))\n",
    "    if not match_list:\n",
    "        match_list = sorted(glob(os.path.join(matches_folder, '*', '*', '*.match')))\n",
    "\n",
    "    # subset to pairs in the image list\n",
    "    image_list_base = [\n",
    "        os.path.splitext(os.path.basename(x))[0].replace('run-','') \n",
    "        for x in image_files\n",
    "        ]\n",
    "    match_list = [\n",
    "        x for x in match_list \n",
    "        if (os.path.dirname(x).split('/')[-1].split('__')[0] in image_list_base)\n",
    "        & (os.path.dirname(x).split('/')[-1].split('__')[1] in image_list_base)\n",
    "        ]\n",
    "    if verbose:\n",
    "        print(f'Copying {len(match_list)} matches to output folder')\n",
    "\n",
    "    for match_file in match_list:\n",
    "        match_out_file = (\n",
    "            output_prefix + '-' \n",
    "            + os.path.dirname(match_file).split('/')[-1] \n",
    "            + '.match'\n",
    "            )\n",
    "        _ = shutil.copy2(match_file, match_out_file)\n",
    "\n",
    "\n",
    "def reduce_asp_match_file(\n",
    "        match_file: str = None, \n",
    "        out_file: str = None,\n",
    "        num_pts: int = 100\n",
    "        ):\n",
    "\n",
    "    # --- Convert match files from binary -> text ---\n",
    "    match_txt = match_file.replace('.match', '_match.txt')\n",
    "    if not os.path.exists(match_txt):\n",
    "        cmd = [match_file, match_txt]\n",
    "        run_cmd('parse_match_file.py', cmd)\n",
    "\n",
    "    # --- Reduce the number of feature matches ---\n",
    "    with open(match_txt, 'r') as f:\n",
    "        lines = [l.strip() for l in f if l.strip()]\n",
    "\n",
    "    if not lines:\n",
    "        print(f\"Empty match file: {match_txt}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Parse header (number of match points per image)\n",
    "    try:\n",
    "        n1, n2 = np.array(lines[0].split()).astype(int)\n",
    "    except Exception as e:\n",
    "        print(f\"Invalid header in {match_txt}: {lines[0]}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    img1_matches = lines[1:1+n1]\n",
    "    img2_matches = lines[1+n1:1+n1+n2]\n",
    "\n",
    "    if not img1_matches or not img2_matches:\n",
    "        print(f\"Incomplete match file: {match_txt}. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Subsample\n",
    "    new_samps = max(1, int(n1 / num_pts))\n",
    "    img1_matches = img1_matches[::new_samps]\n",
    "    img2_matches = img2_matches[::new_samps]\n",
    "\n",
    "    # Update header\n",
    "    n1_new = len(img1_matches)\n",
    "    n2_new = len(img2_matches)\n",
    "    header_line = f\"{n1_new} {n2_new}\"\n",
    "\n",
    "    # Write reduced match text\n",
    "    match_txt_reduced = match_txt.replace('.txt', '_reduced.txt')\n",
    "    with open(match_txt_reduced, 'w') as f:\n",
    "        f.write(header_line + '\\n')\n",
    "        f.write('\\n'.join(img1_matches) + '\\n')\n",
    "        f.write('\\n'.join(img2_matches) + '\\n')\n",
    "\n",
    "    # --- Convert reduced text -> binary ---\n",
    "    cmd = ['-rev', match_txt_reduced, out_file]\n",
    "    run_cmd('parse_match_file.py', cmd)\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def run_ba(\n",
    "        image_list: list[str] = None, \n",
    "        cam_folder: str = None, \n",
    "        output_prefix: str = None,\n",
    "        refdem_file: str = None, \n",
    "        refdem_uncertainty: float = 5, \n",
    "        skip_matching: bool = False,\n",
    "        threads_string: str = \"all\",\n",
    "        verbose: bool = True\n",
    "        ):\n",
    "    output_folder = os.path.dirname(output_prefix)\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # determine how many threads to use\n",
    "    if threads_string==\"all\":\n",
    "        threads = os.cpu_count()\n",
    "    else:\n",
    "        threads = int(threads_string)\n",
    "    if verbose:\n",
    "        print(f'Using up to {threads} threads for each process.')\n",
    "\n",
    "    # get the cameras for each image\n",
    "    cam_list = [find_matching_camera_file(x, cam_folder) for x in image_list]\n",
    "\n",
    "    # construct the arguments\n",
    "    args = [\n",
    "        \"--threads\", str(threads),\n",
    "        \"--num-iterations\", \"500\",\n",
    "        \"--num-passes\", \"2\",\n",
    "        \"--inline-adjustments\",\n",
    "        \"--save-cnet-as-csv\",\n",
    "        \"--min-matches\", \"4\",\n",
    "        \"--disable-tri-ip-filter\",\n",
    "        \"--ip-per-tile\", \"4000\",\n",
    "        \"--ip-inlier-factor\", \"0.2\",\n",
    "        \"--ip-num-ransac-iterations\", \"1000\",\n",
    "        \"--skip-rough-homography\", \n",
    "        \"--min-triangulation-angle\", \"0.0001\",\n",
    "        \"--remove-outliers-params\", \"75 3 5 6\",\n",
    "        \"--individually-normalize\",\n",
    "        \"-o\", output_prefix\n",
    "        ] + image_list + cam_list\n",
    "\n",
    "    if skip_matching:\n",
    "        args += [\"--force-reuse-match-files\"]\n",
    "        args += [\"--skip-matching\"]\n",
    "    if refdem_file:\n",
    "        args += [\"--heights-from-dem\", refdem_file]\n",
    "        args += [\"--heights-from-dem-uncertainty\", str(refdem_uncertainty)]\n",
    "\n",
    "    # run bundle adjust\n",
    "    log = run_cmd('parallel_bundle_adjust', args)\n",
    "\n",
    "    # write log to file\n",
    "    dt_now = datetime.now()\n",
    "    dt_now_string = str(dt_now).replace('-','').replace(' ','').replace(':','').replace('.','')\n",
    "    log_file = output_prefix + f'-parallel_bundle_adjust_{dt_now_string}.log'\n",
    "    with open(log_file, 'w') as f:\n",
    "        f.write(log)\n",
    "    \n",
    "    if verbose:\n",
    "        print('Saved compiled log to file:', log_file)\n",
    "        print('Bundle adjust complete.')\n",
    "        \n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3998cd",
   "metadata": {},
   "source": [
    "## Convert images to single band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51048f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(new_img_folder, exist_ok=True)\n",
    "\n",
    "print('Saving first band of each image. Only single-band images allowed by ASP.')\n",
    "for img in tqdm(img_list):\n",
    "    out_img = os.path.join(new_img_folder, os.path.basename(img))\n",
    "    if os.path.exists(out_img):\n",
    "        continue\n",
    "    args = [\n",
    "        \"-b\", \"1\",\n",
    "        img, out_img\n",
    "    ]\n",
    "    run_cmd(\"gdal_translate\", args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed1a0bd",
   "metadata": {},
   "source": [
    "## Generate frame cameras and GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a279949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(camgen_folder, exist_ok=True)\n",
    "\n",
    "generate_frame_cameras(\n",
    "    img_list = sorted(glob(os.path.join(new_img_folder, '*.tif'))),\n",
    "    dem_file = refdem_file, \n",
    "    product_level = 'l1b',\n",
    "    out_folder = camgen_folder,\n",
    "    gcp_std = 5\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b4289c",
   "metadata": {},
   "source": [
    "## Initial orthorectification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(init_ortho_folder, exist_ok=True)\n",
    "\n",
    "img_list = [x for x in sorted(glob(os.path.join(new_img_folder, '*.tif')))\n",
    "            if not os.path.exists(os.path.join(init_ortho_folder, os.path.basename(x)))]\n",
    "if img_list:\n",
    "    run_mapproject(\n",
    "        img_list = img_list,\n",
    "        cam_folder = camgen_folder,\n",
    "        out_folder = init_ortho_folder,\n",
    "        dem = refdem_file,\n",
    "        t_res = 1,\n",
    "        t_crs = \"EPSG:32611\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3edbe26",
   "metadata": {},
   "source": [
    "## Incremental bundle adjust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b38048",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_increm_folder = os.path.join(out_folder, 'ba_incremental')\n",
    "os.makedirs(ba_increm_folder, exist_ok=True)\n",
    "\n",
    "# First, identify all overlapping image pairs\n",
    "identify_overlapping_image_pairs(\n",
    "    img_list = sorted(glob(os.path.join(init_ortho_folder, '*.tif'))), \n",
    "    overlap_perc = 40, \n",
    "    utm_epsg = \"EPSG:32611\",\n",
    "    out_folder = ba_increm_folder,\n",
    "    true_stereo = False,\n",
    "    )\n",
    "\n",
    "# Update file names to use original images\n",
    "overlap_txt = os.path.join(ba_increm_folder, 'overlapping_image_pairs.txt')\n",
    "overlap = pd.read_csv(overlap_txt, sep=' ', header=0)\n",
    "overlap['img1'] = [os.path.join(new_img_folder, os.path.basename(x)) for x in overlap['img1']]\n",
    "overlap['img2'] = [os.path.join(new_img_folder, os.path.basename(x)) for x in overlap['img2']]\n",
    "overlap.to_csv(overlap_txt, sep=' ', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67a0b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to plan the incrememtal adjustments before running\n",
    "def plan_incremental_bundle_adjust(\n",
    "    overlap_txt,\n",
    "    out_plan_json,\n",
    "    min_overlap_percent=None,\n",
    "    top_k=2,\n",
    "    verbose = True\n",
    "):\n",
    "    print('\\nPlanning incremental bundle adjustment rounds')\n",
    "    print('--------------------------------------------------')\n",
    "\n",
    "    # Load overlap table\n",
    "    overlap = pd.read_csv(overlap_txt, sep=' ', header=0)\n",
    "    overlap = overlap.sort_values(by='overlap_percent', ascending=False)\n",
    "\n",
    "    if min_overlap_percent:\n",
    "        overlap = overlap[overlap['overlap_percent'] >= min_overlap_percent].copy()\n",
    "\n",
    "    # Start with the most-overlapping pair\n",
    "    img1 = overlap.iloc[0]['img1']\n",
    "    img2 = overlap.iloc[0]['img2']\n",
    "\n",
    "    # Initialize image sets, keeping one image fixed to prevent drift\n",
    "    adjusted_img_list = [img1]\n",
    "    fixed_this_round = [img1]\n",
    "    current_new_imgs = [img2]\n",
    "    unadjusted_img_list = list(set(overlap[['img1', 'img2']].values.ravel()))\n",
    "    unadjusted_img_list = [x for x in unadjusted_img_list if x not in fixed_this_round]\n",
    "    rounds = []\n",
    "    round_num = 1\n",
    "\n",
    "    # Main planning loop\n",
    "    while current_new_imgs:\n",
    "        # --- Plan the current round --- \n",
    "        # Determine pairs to run stereo on this round\n",
    "        # pairs must have either: one unadjusted + one adjusted, or two unadjusted images\n",
    "        pairs_this_round = overlap[\n",
    "            (overlap['img1'].isin(current_new_imgs) & overlap['img2'].isin(set(current_new_imgs + fixed_this_round))) |\n",
    "            (overlap['img2'].isin(current_new_imgs) & overlap['img1'].isin(set(current_new_imgs + fixed_this_round)))\n",
    "        ].copy()\n",
    "        pairs_list = pairs_this_round[['img1', 'img2']].values.tolist()\n",
    "\n",
    "        # Add the round plan\n",
    "        rounds.append({\n",
    "            'round': round_num,\n",
    "            'stereo_pairs': pairs_list,\n",
    "            'adjust_images': list(current_new_imgs),\n",
    "            'fixed_images': fixed_this_round\n",
    "        })\n",
    "\n",
    "        # Update global image lists\n",
    "        adjusted_img_list.extend(current_new_imgs)\n",
    "        for img in current_new_imgs:\n",
    "            if img in unadjusted_img_list:\n",
    "                unadjusted_img_list.remove(img)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\n Planned Round {round_num}\")\n",
    "            print(f\"  Fixed: {len(fixed_this_round)} images\")\n",
    "            print(f\"  Adjusting: {len(current_new_imgs)} images -> {current_new_imgs}\")\n",
    "            print(f\"  Stereo pairs: {len(pairs_this_round)}\")\n",
    "\n",
    "        # --- Set up the next round\n",
    "        # Identify the next images to adjust. They must overlap an already adjusted image.\n",
    "        candidates = overlap[\n",
    "            (overlap['img1'].isin(adjusted_img_list) | overlap['img2'].isin(adjusted_img_list))\n",
    "        ]\n",
    "\n",
    "        scores = {}\n",
    "        for _, row in candidates.iterrows():\n",
    "            imgA, imgB, ov = row['img1'], row['img2'], row['overlap_percent']\n",
    "            if (imgA in adjusted_img_list) and (imgB in unadjusted_img_list):\n",
    "                scores[imgB] = max(scores.get(imgB, 0), ov)\n",
    "            elif (imgB in adjusted_img_list) and (imgA in unadjusted_img_list):\n",
    "                scores[imgA] = max(scores.get(imgA, 0), ov)\n",
    "        if not scores:\n",
    "            if verbose:\n",
    "                print(\"\\nNo more overlapping unadjusted images. Planning complete.\")\n",
    "            break\n",
    "\n",
    "        sorted_imgs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        current_new_imgs = [img for img, _ in sorted_imgs[:top_k]]\n",
    "\n",
    "        # Find overlapping image to fix: adjusted images that overlap to-be-adjusted images\n",
    "        overlapping_fixed = overlap[\n",
    "            (overlap['img1'].isin(current_new_imgs) & overlap['img2'].isin(adjusted_img_list)) |\n",
    "            (overlap['img2'].isin(current_new_imgs) & overlap['img1'].isin(adjusted_img_list))\n",
    "        ]\n",
    "        fixed_this_round = sorted(set(\n",
    "            overlapping_fixed['img1'].tolist() + overlapping_fixed['img2'].tolist()\n",
    "        ))\n",
    "        fixed_this_round = [img for img in fixed_this_round if img in adjusted_img_list]\n",
    "\n",
    "        # Continue to next iteration\n",
    "        round_num += 1\n",
    "\n",
    "    # Save plan as JSON\n",
    "    with open(out_plan_json, 'w') as f:\n",
    "        json.dump(rounds, f, indent=2)\n",
    "\n",
    "    print('Total number of rounds planned:', len(rounds))\n",
    "    print(f\"Saved incremental bundle adjust plan to:\\n{out_plan_json}\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Helper function to run the incremental adjustment plan\n",
    "def run_incremental_bundle_adjust(\n",
    "        ba_plan_json: str = None, \n",
    "        overlap_txt: str = None,\n",
    "        cam_folder: str = None,\n",
    "        output_folder: str = None,\n",
    "        reduce_matches: bool = True,\n",
    "        num_matches: int = 100\n",
    "        ):\n",
    "    \n",
    "    # Load the incremental ba plan\n",
    "    with open(ba_plan_json, 'r') as f:\n",
    "        ba_plan = json.load(f)\n",
    "\n",
    "    # Load the overlapping image pairs (global)\n",
    "    overlap = pd.read_csv(overlap_txt, sep=' ', header=0)\n",
    "    # add a \"pair\" row for easier access of pairs later\n",
    "    overlap['pair'] = overlap.apply(lambda r: tuple(sorted([r['img1'], r['img2']])), axis=1)\n",
    "\n",
    "    # Define bundle adjust base options\n",
    "    ba_opts = [\n",
    "        \"--threads\", str(os.cpu_count()),\n",
    "        \"--num-iterations\", \"500\",\n",
    "        \"--num-passes\", \"2\",\n",
    "        \"--inline-adjustments\",\n",
    "        \"--save-cnet-as-csv\",\n",
    "        \"--min-matches\", \"4\",\n",
    "        \"--disable-tri-ip-filter\",\n",
    "        \"--ip-per-tile\", \"4000\",\n",
    "        \"--ip-inlier-factor\", \"0.2\",\n",
    "        \"--ip-num-ransac-iterations\", \"1000\",\n",
    "        \"--skip-rough-homography\",\n",
    "        \"--min-triangulation-angle\", \"0.0001\",\n",
    "        \"--remove-outliers-params\", \"75 3 5 6\",\n",
    "        \"--individually-normalize\",\n",
    "        \"--force-reuse-match-files\",\n",
    "        \"--skip-matching\"\n",
    "    ]\n",
    "\n",
    "    # Keep track of adjusted cameras\n",
    "    adjusted_cams = {}\n",
    "\n",
    "    # Iterate over rounds\n",
    "    print('\\nRunning incremental bundle adjust (IBA)')\n",
    "    print('--------------------------------------------------')\n",
    "    for i in range(0,2):\n",
    "        round_num = ba_plan[i]['round']\n",
    "        print(f'\\nIBA round {round_num}')\n",
    "\n",
    "        # --- Set up output folder --- \n",
    "        round_string = f\"0{round_num}\" if round_num < 10 else str(round_num)\n",
    "        round_folder = os.path.join(output_folder, f\"round{round_string}\")\n",
    "        round_prefix = os.path.join(round_folder, 'run')\n",
    "        os.makedirs(round_folder, exist_ok=True)\n",
    "\n",
    "        # --- Stereo preprocessing ---\n",
    "        # Subset and save the overlapping pairs dataframe\n",
    "        round_stereo_pairs = ba_plan[i]['stereo_pairs']\n",
    "        round_stereo_pairs_set = set(tuple(sorted(pair)) for pair in round_stereo_pairs)\n",
    "        round_overlap = overlap[overlap['pair'].isin(round_stereo_pairs_set)].copy().reset_index(drop=True)\n",
    "        round_overlap_txt = os.path.join(round_folder, f'round{round_string}_overlapping_image_pairs.txt')\n",
    "        round_overlap.to_csv(round_overlap_txt, sep=' ', index=False)\n",
    "            \n",
    "        # Run stereo preprocessing\n",
    "        print(f'Running stereo preprocessing for {len(round_overlap)} image pairs')\n",
    "        run_stereo(\n",
    "            stereo_pairs_fn = round_overlap_txt,\n",
    "            cam_folder = cam_folder,\n",
    "            out_folder = round_folder,\n",
    "            stop_point = 1,\n",
    "            verbose = False\n",
    "        )\n",
    "\n",
    "        # Copy / reduce match files\n",
    "        match_files = sorted(glob(os.path.join(round_folder, '*', '*', '*.match')))\n",
    "        for match_file in match_files:\n",
    "            match_out_file = round_prefix + '-' + os.path.dirname(match_file).split('/')[-1] + '.match'\n",
    "            # reduce the number of matches if specified\n",
    "            if reduce_matches:           \n",
    "                print(f'Reducing number of per-pair feature matches to {num_matches}')     \n",
    "                reduce_asp_match_file(match_file, match_out_file, num_pts=num_matches)\n",
    "            # otherwise, copy the match file over\n",
    "            else:\n",
    "                _ = shutil.copy2(match_file, match_out_file)\n",
    "\n",
    "        # --- Bundle adjust ---\n",
    "        # Get the image and camera lists\n",
    "        round_images = ba_plan[i]['adjust_images'] + ba_plan[i]['fixed_images']\n",
    "        # For each image, use adjusted camera if available, else original\n",
    "        round_cams = []\n",
    "        for img in round_images:\n",
    "            if img in adjusted_cams:\n",
    "                round_cams.append(adjusted_cams[img])\n",
    "            else:\n",
    "                round_cams.append(find_matching_camera_file(img, cam_folder))\n",
    "        \n",
    "        # Construct the fixed image list\n",
    "        round_fixed_images = ba_plan[i]['fixed_images']\n",
    "        if round_fixed_images:\n",
    "            round_fixed_images_txt = os.path.join(round_folder, f'round{round_string}_fixed_images.txt')\n",
    "            with open(round_fixed_images_txt, 'w') as f:\n",
    "                for img in round_fixed_images:\n",
    "                    f.write(img+'\\n')\n",
    "\n",
    "        # Run bundle adjust\n",
    "        print(f'Running bundle adjust for {len(round_images)-len(round_fixed_images)} moveable and {len(round_fixed_images)} fixed images')\n",
    "        round_args = (\n",
    "            ba_opts \n",
    "            + round_images\n",
    "            + round_cams\n",
    "            + ['-o', round_prefix] \n",
    "            )\n",
    "        if round_fixed_images:\n",
    "            round_args += ['--fixed-image-list', round_fixed_images_txt]\n",
    "        _ = run_cmd('parallel_bundle_adjust', round_args)\n",
    "\n",
    "        # --- Update adjusted cameras ---\n",
    "        out_cam_list = sorted(glob(round_prefix + '*.tsai'))\n",
    "        for cam_file in out_cam_list:\n",
    "            cam_base = os.path.basename(cam_file)\n",
    "            # remove prefix and extension to get the image base name\n",
    "            img_name = cam_base.replace(os.path.basename(round_prefix) + '-', '').replace('.tsai', '') + '.tif'\n",
    "            # only assign cameras for images that were *adjusted* this round\n",
    "            if img_name not in round_fixed_images:\n",
    "                adjusted_cams[img_name] = cam_file\n",
    "            else:\n",
    "                # delete redundant fixed cameras from this round\n",
    "                # APPEARS TO NOT BE WORKING\n",
    "                os.remove(cam_file)\n",
    "\n",
    "        print('Done')\n",
    "    \n",
    "    print('\\nIBA complete!')\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# Make the bundle adjustment plan\n",
    "overlap_txt = os.path.join(ba_increm_folder, 'overlapping_image_pairs.txt')\n",
    "ba_plan_json = os.path.join(ba_increm_folder, 'bundle_adjust_incremental_plan.json')\n",
    "plan_incremental_bundle_adjust(\n",
    "    overlap_txt,\n",
    "    ba_plan_json,\n",
    "    verbose = False\n",
    ")\n",
    "\n",
    "# Run incremental bundle adjust\n",
    "run_incremental_bundle_adjust(\n",
    "    ba_plan_json, \n",
    "    overlap_txt,\n",
    "    cam_folder = camgen_folder,\n",
    "    output_folder = ba_increm_folder,\n",
    "    reduce_matches = False,\n",
    "    # num_matches = 100\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4f2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapproject to check for success\n",
    "\n",
    "cam_list = sorted(glob(os.path.join(ba_increm_folder, '*', '*.tsai')))\n",
    "cam_folder_list = sorted(list(set([os.path.dirname(x) for x in cam_list])))\n",
    "for f in cam_folder_list[0:1]:\n",
    "    cam_f_list = [x for x in cam_list if os.path.dirname(x)==f]\n",
    "    img_list = sorted([os.path.join(new_img_folder, os.path.splitext(os.path.basename(x))[0].replace('run-','') + '.tif') for x in cam_f_list])\n",
    "    run_mapproject(\n",
    "        img_list = img_list,\n",
    "        cam_folder = f,\n",
    "        out_folder = ba_increm_folder,\n",
    "        dem = refdem_file,\n",
    "        t_res = 1,\n",
    "        t_crs = \"EPSG:32611\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b37fd",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a337fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 1. Triplet bundle adjustment #####\n",
    "\n",
    "ba_triplet_folder = os.path.join(out_folder, 'ba_triplets')\n",
    "os.makedirs(ba_triplet_folder, exist_ok=True)\n",
    "\n",
    "# First, identify all overlapping image pairs\n",
    "identify_overlapping_image_pairs(\n",
    "    img_list = sorted(glob(os.path.join(init_ortho_folder, '*.tif'))), \n",
    "    overlap_perc = 10, \n",
    "    utm_epsg = \"EPSG:32611\",\n",
    "    out_folder = ba_triplet_folder,\n",
    "    true_stereo = False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d979953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, identify triplets and within-triplet stereo pairs\n",
    "print('\\nIdentifying triplets')\n",
    "overlap_txt = os.path.join(ba_triplet_folder, 'overlapping_image_pairs.txt')\n",
    "triplets_json, pairs_txt = create_triplets_pairs(overlap_txt, ba_triplet_folder, max_group_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cc0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle adjust\n",
    "\n",
    "# Load the triplets file\n",
    "with open(triplets_json, 'r') as f:\n",
    "    triplets = json.load(f)\n",
    "\n",
    "# PICKING UP AFTER CANCELLING - Just run groups without new cameras\n",
    "sub_keys = [g for g in triplets.keys() if len(glob(os.path.join(ba_triplet_folder, g, '*.tsai'))) < 1]\n",
    "triplets = {key: triplets[key] for key in triplets.keys() if key in sub_keys}\n",
    "\n",
    "# Iterate over groups\n",
    "for g in tqdm(list(triplets.keys())[11:12], desc='Triplets-BA'):\n",
    "    # define output folder and prefix\n",
    "    g_folder = os.path.join(ba_triplet_folder, g)\n",
    "    g_prefix = os.path.join(g_folder, 'run')\n",
    "    os.makedirs(g_folder, exist_ok=True)\n",
    "\n",
    "    # subset stereo pairs to relevant images\n",
    "    g_images = triplets[g]['file_names']\n",
    "    pairs = pd.read_csv(pairs_txt, sep=' ', header=0)\n",
    "    g_pairs = pd.concat([\n",
    "        pairs.loc[(pairs['img1'].isin(g_images)) & (pairs['img2'].isin(g_images))],\n",
    "        pairs.loc[(pairs['img2'].isin(g_images)) & (pairs['img1'].isin(g_images))],\n",
    "    ]).drop_duplicates()\n",
    "    g_pairs_txt = os.path.join(g_folder, f\"{g}_overlapping_image_pairs.txt\")\n",
    "    g_pairs.to_csv(g_pairs_txt, header=True, index=False, sep=' ')\n",
    "\n",
    "    # stereo preprocessing\n",
    "    # print('Running stereo preprocessing for dense feature matching')\n",
    "    # run_stereo(\n",
    "    #     stereo_pairs_fn = g_pairs_txt,\n",
    "    #     cam_folder = camgen_folder,\n",
    "    #     dem_file = refdem_file,\n",
    "    #     out_folder = g_folder,\n",
    "    #     stop_point = 1\n",
    "    # )\n",
    "\n",
    "    # # reduce number of matches\n",
    "    # reduce_asp_match_files(\n",
    "    #     match_folder = g_folder,\n",
    "    #     output_folder = g_folder\n",
    "    # )\n",
    "\n",
    "    # get camera and GCP lists\n",
    "    g_cams = [find_matching_camera_file(x, camgen_folder) for x in g_images]\n",
    "\n",
    "    # bundle adjust\n",
    "    args = [\n",
    "        \"--threads\", \"9\",\n",
    "        \"--num-iterations\", \"500\",\n",
    "        \"--num-passes\", \"2\",\n",
    "        \"--inline-adjustments\",\n",
    "        \"--min-matches\", \"4\",\n",
    "        \"--individually-normalize\",\n",
    "        \"--heights-from-dem\", refdem_file,\n",
    "        \"--heights-from-dem-uncertainty\", \"1\",\n",
    "        \"--force-reuse-match-files\",\n",
    "        \"--skip-matching\",\n",
    "        \"-o\", g_prefix\n",
    "        ] + g_images + g_cams\n",
    "\n",
    "    # run bundle adjust\n",
    "    log = run_cmd('parallel_bundle_adjust', args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a181cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TESTING MAPPROJECT AFTER BA TRIPLETS\n",
    "\n",
    "g_folder = os.path.join(ba_triplet_folder, 'group_11')\n",
    "cam_list = glob(os.path.join(g_folder, '*.tsai'))\n",
    "cam_list_base = [os.path.splitext(os.path.basename(x))[0].replace('run-','') for x in cam_list]\n",
    "img_list = sorted(glob(os.path.join(new_img_folder, '*.tif')))\n",
    "img_list = [x for x in img_list if os.path.splitext(os.path.basename(x))[0] in cam_list_base]\n",
    "\n",
    "run_mapproject(\n",
    "    img_list = img_list,\n",
    "    cam_folder = g_folder,\n",
    "    out_folder = g_folder,\n",
    "    dem = refdem_file,\n",
    "    t_res = 0.8,\n",
    "    t_crs = \"EPSG:32611\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d017d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy adjusted cameras to root ba_triplet_folder\n",
    "cam_list = sorted(glob(os.path.join(ba_triplet_folder, '*', '*.tsai')))\n",
    "for cam in tqdm(cam_list):\n",
    "    cam_out = os.path.join(ba_triplet_folder, os.path.basename(cam))\n",
    "    _ = shutil.copy2(cam, cam_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef776917",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 2. Global bundle adjustment #####\n",
    "\n",
    "ba_global_folder = os.path.join(out_folder, 'ba_global')\n",
    "os.makedirs(ba_global_folder, exist_ok=True)\n",
    "\n",
    "# --- Stereo preprocessing ---\n",
    "# Identify overlapping pairs that were not bundle adjusted together\n",
    "overlap = pd.read_csv(overlap_txt, sep=' ', header=0)\n",
    "stereo_pairs = pd.read_csv(pairs_txt, sep=' ', header=0)\n",
    "merged_df = pd.merge(overlap, stereo_pairs, how='left', indicator=True)\n",
    "overlap_filtered = merged_df[merged_df['_merge'] == 'left_only'].drop(columns=['_merge']).reset_index(drop=True)\n",
    "\n",
    "# Subset to overlap > 40%\n",
    "overlap_filtered = overlap_filtered.loc[overlap_filtered['overlap_percent'] > 40].reset_index(drop=True)\n",
    "\n",
    "# Save to file\n",
    "overlap_filtered_txt = os.path.join(ba_global_folder, 'stereo_pairs.txt')\n",
    "overlap_filtered.to_csv(overlap_filtered_txt, sep=' ', header=True, index=False)\n",
    "print('Saved stereo pairs to file:', overlap_filtered_txt)\n",
    "\n",
    "# Run stereo preprocessing\n",
    "ba_global_stereo_folder = os.path.join(ba_global_folder, 'feature_matches')\n",
    "run_stereo(\n",
    "    stereo_pairs_fn = overlap_filtered_txt,\n",
    "    cam_folder = ba_triplet_folder,\n",
    "    dem_file = refdem_file,\n",
    "    out_folder = ba_global_stereo_folder,\n",
    "    stop_point = 1\n",
    ")\n",
    "\n",
    "# --- Reduce number of matches ---\n",
    "reduce_asp_match_files(\n",
    "    match_folder = os.path.join(ba_global_folder, 'feature_matches'),\n",
    "    output_folder = ba_global_folder\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecddd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bundle adjust with one triplet fixed ---\n",
    "cam_list = sorted(glob(os.path.join(ba_triplet_folder, '*.tsai')))\n",
    "cam_list_base = [os.path.splitext(os.path.basename(x))[0].replace('run-','') for x in cam_list]\n",
    "image_list = [os.path.join(init_ortho_folder, x + '.tif') for x in cam_list_base]\n",
    "\n",
    "# Fix one triplet group\n",
    "with open(triplets_json, 'r') as f:\n",
    "    triplets = json.load(f)\n",
    "max_length = max(np.array([triplets[g]['length'] for g in triplets.keys()]))\n",
    "fixed_g = [g for g in triplets.keys() if triplets[g]['length']==max_length][0]\n",
    "print(f'Using triplet {fixed_g} as an anchor.')\n",
    "fixed_images = triplets[fixed_g]['file_names']\n",
    "fixed_image_txt = os.path.join(ba_global_folder, 'fixed_images.txt')\n",
    "with open(fixed_image_txt, 'w') as f:\n",
    "    f.write(' '.join(fixed_images))\n",
    "print('Saved list of fixed images to file:', fixed_image_txt)\n",
    "\n",
    "# Run bundle adjust\n",
    "print('Running global bundle adjust')\n",
    "args = [\n",
    "    \"--threads\", \"9\",\n",
    "    \"--num-iterations\", \"500\",\n",
    "    \"--num-passes\", \"2\",\n",
    "    \"--inline-adjustments\",\n",
    "    \"--min-matches\", \"4\",\n",
    "    \"--individually-normalize\",\n",
    "    \"--fixed-image-list\", fixed_image_txt,\n",
    "    \"--force-reuse-match-files\",\n",
    "    \"--skip-matching\",\n",
    "    \"-o\", os.path.join(ba_global_folder, 'run')\n",
    "    ] + image_list + cam_list\n",
    "\n",
    "# run bundle adjust\n",
    "log = run_cmd('parallel_bundle_adjust', args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d85a2e",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165686d",
   "metadata": {},
   "source": [
    "## Intermediate ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a389891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interm_ortho_folder = os.path.join(out_folder, 'interm_ortho')\n",
    "os.makedirs(interm_ortho_folder, exist_ok=True)\n",
    "\n",
    "# get only images with successful cameras\n",
    "cam_list = glob(os.path.join(ba_global_folder, '*.tsai'))\n",
    "cam_list_base = [os.path.splitext(os.path.basename(x))[0].replace('run-run-','') for x in cam_list]\n",
    "img_list = sorted(glob(os.path.join(new_img_folder, '*.tif')))\n",
    "img_list = [x for x in img_list if os.path.splitext(os.path.basename(x))[0] in cam_list_base]\n",
    "\n",
    "run_mapproject(\n",
    "    img_list = img_list,\n",
    "    cam_folder = ba_global_folder,\n",
    "    out_folder = interm_ortho_folder,\n",
    "    dem = refdem_file,\n",
    "    t_res = 0.8,\n",
    "    t_crs = \"EPSG:32611\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16c40c0",
   "metadata": {},
   "source": [
    "## Final stereo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930dbb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(final_stereo_folder, exist_ok=True)\n",
    "img_list = sorted(glob(os.path.join(interm_ortho_folder, '*.tif')))\n",
    "\n",
    "# Create list of stereo pairs\n",
    "identify_overlapping_image_pairs(\n",
    "    img_list, \n",
    "    overlap_perc = 40, \n",
    "    utm_epsg = \"EPSG:32611\",\n",
    "    out_folder = final_stereo_folder,\n",
    "    )\n",
    "overlap_txt = os.path.join(final_stereo_folder, 'overlapping_image_pairs.txt')\n",
    "\n",
    "# Run stereo\n",
    "run_stereo(\n",
    "    stereo_pairs_fn = overlap_txt,\n",
    "    cam_folder = ba_global_folder,\n",
    "    dem_fn = refdem_file,\n",
    "    out_folder = final_stereo_folder,\n",
    "    correlator_mode = False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88df7824",
   "metadata": {},
   "source": [
    "## DSM mosaicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b205ebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a926455",
   "metadata": {},
   "source": [
    "## DSM coregistration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c60c63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "469043cb",
   "metadata": {},
   "source": [
    "## Final ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d24af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_mapproject(img_list: List[str] = None, \n",
    "#                    cam_folder: str = None, \n",
    "#                    ba_prefix: str = None,\n",
    "#                    out_folder: str = None, \n",
    "#                    dem: str = 'WGS84', \n",
    "#                    t_res: float = None, \n",
    "#                    t_crs: str = None, \n",
    "#                    session: str = None, \n",
    "#                    orthomosaic: bool = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac47bb81",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c9b15e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skysat_stereo_snow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
